{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA7UTv0pvATc"
      },
      "source": [
        "# RAG 파이프라인에 Rewriter를 적용한 코드입니다.\n",
        "\n",
        "✅ 질문 리라이터(Question Rewriter)는 사용자의 원래 질문을 더 검색에 적합한 형태로 변환해주는 NLP 컴포넌트입니다. 특히 RAG, QA, 챗봇 시스템에서 검색 정확도를 높이는 데 매우 중요한 역할을 합니다.\n",
        "\n",
        "**질문 리라이터 (Query Rewriter / Question Rewriter)** 는 다음을 수행합니다:\n",
        "\n",
        "- ✅ 사용자의 불완전하거나 모호한 질문을\n",
        "- ✅ **명확하고, 문맥이 포함된 형태로 변환**해서\n",
        "- ✅ **retriever가 더 정확한 문서나 청크를 검색할 수 있도록** 도와줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfV42Er6tDWn"
      },
      "source": [
        "    base_folder_path = \"/content/drive/MyDrive/nomu_dataset3\" # <<< 원본 데이터 폴더 경로 확인!\n",
        "    result_dir = \"/content/drive/MyDrive/nomu_rag_result\"    # <<< 결과 저장 폴더 경로 확인!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIL128MhoqWr"
      },
      "source": [
        "# 0: 필요한 라이브러리 설치 (OpenAI 추가)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKVnkOgotFA",
        "outputId": "03e7eca8-5ed5-44ed-89d7-d138557d026c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 단계 0: 라이브러리 설치 시작 (OpenAI 추가) ---\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.6/746.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "[알림] 라이브러리 설치/업데이트 완료. langchain-openai, openai 추가됨.\n"
          ]
        }
      ],
      "source": [
        "# === 단계 0: 필요한 라이브러리 설치 (의존성 충돌 해결 버전 + OpenAI 추가) ===\n",
        "print(\"--- 단계 0: 라이브러리 설치 시작 (OpenAI 추가) ---\")\n",
        "!pip install -qU \\\n",
        "    langchain langchain-core langchain-community langchain-openai openai \\\n",
        "    pypdf openpyxl xlrd unstructured faiss-cpu sentence-transformers \\\n",
        "    pdf2image pillow pdfminer.six rank_bm25 pillow-heif jq \\\n",
        "    google-api-python-client google-auth-httplib2 google-auth-oauthlib gspread \\\n",
        "    ragas datasets \\\n",
        "    pandas==2.2.2 \\\n",
        "    PyPDF2 \\\n",
        "    fsspec==2025.3.2 # <<< fsspec 버전은 환경에 따라 조정 필요, 원래 버전 사용\n",
        "\n",
        "# google-ai-generativelanguage는 OpenAI 사용 시 필수는 아님 (필요시 유지)\n",
        "# !pip install -qU google-ai-generativelanguage==0.6.15\n",
        "\n",
        "print(\"\\n[알림] 라이브러리 설치/업데이트 완료. langchain-openai, openai 추가됨.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw9hai20pM7K"
      },
      "source": [
        "# 1: 기본 및 필요 라이브러리 임포트 (OpenAI LLM 임포트 추가)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezNk5hE9pQv_",
        "outputId": "e8e84c73-d75d-412b-c972-070e574d1acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 단계 1: 라이브러리 임포트 완료 (ChatOpenAI 임포트됨) ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 1: 기본 및 필요 라이브러리 임포트 ===\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "import pandas as pd\n",
        "from google.colab import drive, auth, userdata\n",
        "import PyPDF2 # 명시적 임포트\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import gspread\n",
        "from google.auth import default as google_auth_default\n",
        "from datasets import Dataset\n",
        "import re\n",
        "import traceback # 오류 상세 출력을 위해 추가\n",
        "\n",
        "# LangChain 관련 임포트\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import (\n",
        "    PyPDFLoader, UnstructuredExcelLoader, CSVLoader,\n",
        "    UnstructuredFileLoader, DirectoryLoader, GoogleDriveLoader\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain_google_genai import GoogleGenerativeAIEmbeddings # Google 임베딩 (필요 시 유지)\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # HuggingFace 임베딩 (유지)\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "# === LLM 임포트 변경 ===\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI # <<< 삭제 또는 주석 처리\n",
        "from langchain_openai import ChatOpenAI # <<< OpenAI LLM 클래스 임포트\n",
        "# =======================\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# RAGAS 관련 임포트 (기존 유지)\n",
        "try:\n",
        "    from ragas import evaluate\n",
        "    from ragas.metrics import context_precision, context_recall, faithfulness, answer_relevancy\n",
        "    from ragas.llms import LangchainLLMWrapper\n",
        "    from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "except ImportError:\n",
        "    print(\"!! Ragas 관련 라이브러리가 설치되지 않았습니다. 평가 단계 전에 설치가 필요합니다.\")\n",
        "    LangchainLLMWrapper = None; LangchainEmbeddingsWrapper = None; context_precision = None; context_recall = None; faithfulness = None; answer_relevancy = None\n",
        "\n",
        "# 기타 평가 관련 임포트 (기존 유지)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "# import google.generativeai as genai # OpenAI 사용 시 필수는 아님\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") # 경고 메시지 숨기기\n",
        "\n",
        "print(\"--- 단계 1: 라이브러리 임포트 완료 (ChatOpenAI 임포트됨) ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGJ0cARZcM64",
        "outputId": "5a3fe889-4866-45f2-f68b-c8a33962e160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2.15\n"
          ]
        }
      ],
      "source": [
        "import ragas\n",
        "print(ragas.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDH4-J6prCU"
      },
      "source": [
        "# 2: 환경 설정 (OpenAI API 키 추가)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLV3INSgrLZi"
      },
      "source": [
        "    base_folder_path = \"/content/drive/MyDrive/nomu_dataset3\" # <<< 원본 데이터 폴더 경로 확인!\n",
        "    result_dir = \"/content/drive/MyDrive/nomu_rag_result\"    # <<< 결과 저장 폴더 경로 확인!\n",
        "    # <<< nomu_dataset3 폴더의 실제 ID로 변경하거나 확인! >>>\n",
        "예)\n",
        "    https://drive.google.com/drive/u/0/folders/1FIA_HGeYbRVaH_USuxUdjhFAoReUTo9U\n",
        "\n",
        "target_folder_id = \"1FIA_HGeYbRVaH_USuxUdjhFAoReUTo9U\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3MRw_Yupuun",
        "outputId": "aea9cf9f-1f15-479d-a4ee-9c8da30ec187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 2: 환경 설정 시작 ---\n",
            "Mounted at /content/drive\n",
            "[성공] Google Drive 마운트 완료.\n",
            "[성공] Google Colab 사용자 인증 완료.\n",
            "[성공] OpenAI API 키 로드 및 설정 완료.\n",
            "데이터 소스 검색 경로: /content/drive/MyDrive/nomu_dataset3\n",
            "결과 저장 경로: /content/drive/MyDrive/nomu_rag_result\n",
            "Google Sheets 검색 대상 폴더 ID: 1FIA_HGeYbRVaH_USuxUdjhFAoReUTo9U\n",
            "--- 단계 2: 환경 설정 완료 (OpenAI API 키 설정됨) ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 2: 환경 설정 (Drive 마운트, API 키, 경로) ===\n",
        "print(\"\\n--- 단계 2: 환경 설정 시작 ---\")\n",
        "\n",
        "# --- Google Drive 마운트 (기존 유지) ---\n",
        "DRIVE_MOUNTED = False\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    DRIVE_MOUNTED = True\n",
        "    print(\"[성공] Google Drive 마운트 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"[실패] Google Drive 마운트 오류: {e}\")\n",
        "\n",
        "# --- Google 인증 (Colab 사용자 인증 - 필요시 유지) ---\n",
        "# Google Drive Loader 등을 사용한다면 인증 유지 필요\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    print(\"[성공] Google Colab 사용자 인증 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"[실패] Google Colab 인증 오류: {e}\")\n",
        "\n",
        "# === API 키 설정 변경 ===\n",
        "# --- OpenAI API 키 설정 ---\n",
        "OPENAI_API_KEY = None\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') # Colab Secrets 우선 확인\n",
        "    if not OPENAI_API_KEY: OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') # 환경 변수 확인\n",
        "    if not OPENAI_API_KEY: raise ValueError(\"OpenAI API 키를 Colab Secrets 또는 환경 변수에서 찾을 수 없습니다.\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "    print(\"[성공] OpenAI API 키 로드 및 설정 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"[실패] OpenAI API 키 로드/설정 오류: {e}\")\n",
        "    print(\"   !! OpenAI API 키 없이는 이후 LLM, RAGAS 평가 등 사용 불가 !!\")\n",
        "\n",
        "# --- Google AI API 키 설정 (선택 사항) ---\n",
        "# 만약 Google Embedding 등을 계속 사용한다면 유지, 아니면 제거 가능\n",
        "# GOOGLE_API_KEY = None\n",
        "# try:\n",
        "#     GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "#     if not GOOGLE_API_KEY: GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
        "#     if GOOGLE_API_KEY:\n",
        "#         os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "#         import google.generativeai as genai\n",
        "#         genai.configure(api_key=GOOGLE_API_KEY)\n",
        "#         print(\"[정보] Google API 키 로드 및 설정 완료 (선택 사항).\")\n",
        "#     # else: print(\"[정보] Google API 키 로드 안 됨 (선택 사항).\") # 키 없어도 오류 아님\n",
        "# except Exception as e: print(f\"[경고] Google API 키 설정 중 오류 발생 (선택 사항): {e}\")\n",
        "# =========================\n",
        "\n",
        "# --- 경로 설정 (기존 유지) ---\n",
        "if DRIVE_MOUNTED:\n",
        "    base_folder_path = \"/content/drive/MyDrive/nomu_dataset3\"\n",
        "    result_dir = \"/content/drive/MyDrive/nomu_rag_result\"\n",
        "else:\n",
        "    base_folder_path = \"./nomu_data_local\"\n",
        "    result_dir = \"./nomu_rag_result_local\"\n",
        "\n",
        "print(f\"데이터 소스 검색 경로: {base_folder_path}\")\n",
        "print(f\"결과 저장 경로: {result_dir}\")\n",
        "os.makedirs(base_folder_path, exist_ok=True)\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "# Google Sheets 폴더 ID (필요시 유지)\n",
        "target_folder_id = \"1FIA_HGeYbRVaH_USuxUdjhFAoReUTo9U\"\n",
        "print(f\"Google Sheets 검색 대상 폴더 ID: {target_folder_id}\")\n",
        "\n",
        "# --- 결과 파일 경로 (기존 유지) ---\n",
        "vs_status_file = os.path.join(result_dir, \"vectorstore_build_status.json\")\n",
        "vs_checkpoint_path = os.path.join(result_dir, \"faiss_index_nomu_checkpoint\")\n",
        "vs_final_save_path = os.path.join(result_dir, \"faiss_index_nomu_final\")\n",
        "bm25_data_save_path = os.path.join(result_dir, \"split_texts_for_bm25.pkl\")\n",
        "\n",
        "print(\"--- 단계 2: 환경 설정 완료 (OpenAI API 키 설정됨) ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCfN-QxxMJUP"
      },
      "source": [
        "# 3: LLM 두 개 선언"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uf-nA4RSqIe"
      },
      "source": [
        "qa_llm → RetrievalQA 체인의 LLM으로 사용\n",
        "\n",
        "eval_llm → LangchainLLM(llm=eval_llm) 로 RAGAS evaluate() 함수에 들어감"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0nlwj3SsxU"
      },
      "source": [
        "평가 모델(eval_llm)은 고정해두는 게 비교 분석할 때 더 일관성 있어요\n",
        "\n",
        "응답 생성용(qa_llm)은 실험적으로 변경해가며 비교하면 좋아요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bbqErOISMq"
      },
      "source": [
        "리트리버 결과(source documents) 평가할 때도 eval_llm을 사용합니다.\n",
        "\n",
        "생성된 답변(result) 평가할 때도 eval_llm을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWrqrj3XMCk5"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 응답 생성용 LLM\n",
        "qa_llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "# 평가용 LLM (RAGAS용)\n",
        "eval_llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4.1-nano\",\n",
        "    temperature=0,\n",
        "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AC7tRibqyM4"
      },
      "source": [
        "# 4: 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK4AoDtiq8s2",
        "outputId": "65c11435-446a-47a1-9da8-3b523dc11684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 4: 데이터 로딩 시작 ---\n",
            "\n",
            "--- 4.1 Google Sheets 파일 로딩 ---\n",
            "  GoogleDriveLoader로 폴더 '1FIA_HGeYbRVaH_USuxUdjhFAoReUTo9U' 로딩 중...\n",
            "  [성공] Google Sheets 로딩 (89개 조각).\n",
            "\n",
            "--- 4.2 다른 파일 형식 로딩 (DirectoryLoader) ---\n",
            "\n",
            "  '.pdf' 확장자 로딩 (/content/drive/MyDrive/nomu_dataset3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:00<00:41,  3.01it/s]\u001b[A\n",
            "  2%|▏         | 2/125 [00:01<01:08,  1.78it/s]\u001b[A\n",
            "  3%|▎         | 4/125 [00:01<00:32,  3.74it/s]\u001b[A\n",
            "  4%|▍         | 5/125 [00:01<00:40,  2.97it/s]\u001b[A\n",
            "  5%|▍         | 6/125 [00:02<00:45,  2.61it/s]\u001b[A\n",
            "  6%|▌         | 7/125 [00:02<00:45,  2.59it/s]\u001b[A\n",
            "  6%|▋         | 8/125 [00:02<00:35,  3.27it/s]\u001b[A\n",
            "  7%|▋         | 9/125 [00:02<00:34,  3.40it/s]\u001b[A\n",
            "  8%|▊         | 10/125 [00:03<00:29,  3.96it/s]\u001b[A\n",
            "  9%|▉         | 11/125 [00:03<00:25,  4.43it/s]\u001b[A\n",
            " 10%|▉         | 12/125 [00:03<00:38,  2.94it/s]\u001b[A\n",
            " 10%|█         | 13/125 [00:04<00:34,  3.24it/s]\u001b[A\n",
            " 11%|█         | 14/125 [00:04<00:27,  4.02it/s]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:04<00:29,  3.68it/s]\u001b[A\n",
            "100%|██████████| 125/125 [01:10<00:00, 10.96it/s]\n",
            " 14%|█▎        | 17/125 [00:05<00:44,  2.43it/s]\u001b[A\n",
            " 14%|█▍        | 18/125 [00:05<00:43,  2.44it/s]\u001b[A\n",
            " 15%|█▌        | 19/125 [00:06<00:46,  2.28it/s]\u001b[A\n",
            " 16%|█▌        | 20/125 [00:06<00:40,  2.61it/s]\u001b[A\n",
            " 17%|█▋        | 21/125 [00:07<00:57,  1.80it/s]\u001b[A\n",
            " 18%|█▊        | 22/125 [00:07<00:44,  2.33it/s]\u001b[A\n",
            " 18%|█▊        | 23/125 [00:09<01:10,  1.45it/s]\u001b[A\n",
            " 19%|█▉        | 24/125 [00:09<01:10,  1.43it/s]\u001b[A\n",
            " 21%|██        | 26/125 [00:10<00:42,  2.30it/s]\u001b[A\n",
            " 22%|██▏       | 28/125 [00:10<00:33,  2.87it/s]\u001b[A\n",
            " 23%|██▎       | 29/125 [00:10<00:33,  2.86it/s]\u001b[A\n",
            " 24%|██▍       | 30/125 [00:11<00:45,  2.08it/s]\u001b[A\n",
            " 25%|██▍       | 31/125 [00:11<00:44,  2.12it/s]\u001b[A\n",
            " 26%|██▌       | 32/125 [00:11<00:36,  2.53it/s]\u001b[A\n",
            " 26%|██▋       | 33/125 [00:12<00:34,  2.68it/s]\u001b[A\n",
            " 27%|██▋       | 34/125 [00:12<00:27,  3.27it/s]\u001b[A\n",
            " 28%|██▊       | 35/125 [00:12<00:28,  3.21it/s]\u001b[A\n",
            " 29%|██▉       | 36/125 [00:13<00:27,  3.22it/s]\u001b[A\n",
            " 30%|██▉       | 37/125 [00:15<01:09,  1.26it/s]\u001b[A\n",
            " 30%|███       | 38/125 [00:15<00:59,  1.47it/s]\u001b[A\n",
            " 31%|███       | 39/125 [00:15<00:51,  1.66it/s]\u001b[A\n",
            " 32%|███▏      | 40/125 [00:15<00:37,  2.28it/s]\u001b[A\n",
            " 33%|███▎      | 41/125 [00:16<00:32,  2.62it/s]\u001b[A\n",
            " 34%|███▎      | 42/125 [00:16<00:22,  3.64it/s]\u001b[A\n",
            " 34%|███▍      | 43/125 [00:16<00:19,  4.20it/s]\u001b[A\n",
            " 35%|███▌      | 44/125 [00:16<00:19,  4.09it/s]\u001b[A\n",
            " 36%|███▌      | 45/125 [00:16<00:22,  3.55it/s]\u001b[A\n",
            " 37%|███▋      | 46/125 [00:16<00:20,  3.82it/s]\u001b[A\n",
            " 38%|███▊      | 47/125 [00:17<00:21,  3.66it/s]\u001b[A\n",
            " 39%|███▉      | 49/125 [00:17<00:16,  4.59it/s]\u001b[A\n",
            " 39%|███▉      | 49/125 [00:17<00:16,  4.59it/s]\u001b[A\n",
            " 41%|████      | 51/125 [00:17<00:11,  6.48it/s]\u001b[A\n",
            " 42%|████▏     | 53/125 [00:17<00:08,  8.36it/s]\u001b[A\n",
            " 44%|████▍     | 55/125 [00:17<00:07,  9.39it/s]\u001b[A\n",
            " 45%|████▍     | 56/125 [00:17<00:06, 10.47it/s]\u001b[A\n",
            " 47%|████▋     | 59/125 [00:18<00:07,  8.66it/s]\u001b[A\n",
            " 49%|████▉     | 61/125 [00:18<00:08,  7.89it/s]\u001b[A\n",
            " 51%|█████     | 64/125 [00:18<00:05, 10.88it/s]\u001b[A\n",
            " 53%|█████▎    | 66/125 [00:19<00:09,  6.45it/s]\u001b[A\n",
            " 54%|█████▍    | 68/125 [00:21<00:22,  2.54it/s]\u001b[A\n",
            " 55%|█████▌    | 69/125 [00:21<00:19,  2.84it/s]\u001b[A\n",
            " 56%|█████▌    | 70/125 [00:21<00:14,  3.78it/s]\u001b[A\n",
            " 57%|█████▋    | 71/125 [00:21<00:13,  4.10it/s]\u001b[A\n",
            " 58%|█████▊    | 72/125 [00:21<00:13,  3.93it/s]\u001b[A\n",
            " 58%|█████▊    | 73/125 [00:22<00:20,  2.59it/s]\u001b[A\n",
            " 59%|█████▉    | 74/125 [00:23<00:20,  2.53it/s]\u001b[A\n",
            " 60%|██████    | 75/125 [00:23<00:17,  2.84it/s]\u001b[A\n",
            " 61%|██████    | 76/125 [00:24<00:25,  1.94it/s]\u001b[A\n",
            " 62%|██████▏   | 77/125 [00:24<00:22,  2.17it/s]\u001b[A\n",
            " 63%|██████▎   | 79/125 [00:24<00:11,  4.17it/s]\u001b[A\n",
            " 63%|██████▎   | 79/125 [00:24<00:11,  4.17it/s]\u001b[A\n",
            " 65%|██████▍   | 81/125 [00:24<00:09,  4.77it/s]\u001b[A\n",
            " 66%|██████▋   | 83/125 [00:25<00:11,  3.53it/s]\u001b[A\n",
            " 66%|██████▋   | 83/125 [00:25<00:11,  3.53it/s]\u001b[A\n",
            " 67%|██████▋   | 84/125 [00:25<00:11,  3.71it/s]\u001b[A\n",
            " 68%|██████▊   | 85/125 [00:26<00:12,  3.26it/s]\u001b[A\n",
            " 69%|██████▉   | 86/125 [00:26<00:13,  2.97it/s]\u001b[A\n",
            " 70%|██████▉   | 87/125 [00:26<00:13,  2.86it/s]\u001b[A\n",
            " 70%|███████   | 88/125 [00:27<00:14,  2.55it/s]\u001b[A\n",
            " 71%|███████   | 89/125 [00:27<00:11,  3.10it/s]\u001b[A\n",
            " 72%|███████▏  | 90/125 [00:27<00:09,  3.68it/s]\u001b[A\n",
            " 73%|███████▎  | 91/125 [00:27<00:06,  5.23it/s]\u001b[A\n",
            " 74%|███████▎  | 92/125 [00:28<00:07,  4.26it/s]\u001b[A\n",
            " 74%|███████▍  | 93/125 [00:28<00:07,  4.53it/s]\u001b[A\n",
            " 75%|███████▌  | 94/125 [00:28<00:06,  5.08it/s]\u001b[A\n",
            " 76%|███████▌  | 95/125 [00:28<00:04,  6.63it/s]\u001b[A\n",
            " 78%|███████▊  | 98/125 [00:28<00:03,  8.34it/s]\u001b[A\n",
            " 78%|███████▊  | 98/125 [00:28<00:03,  8.34it/s]\u001b[A\n",
            " 79%|███████▉  | 99/125 [00:30<00:09,  2.88it/s]\u001b[A\n",
            " 80%|████████  | 100/125 [00:30<00:08,  2.79it/s]\u001b[A\n",
            " 81%|████████  | 101/125 [00:30<00:07,  3.16it/s]\u001b[A\n",
            " 82%|████████▏ | 103/125 [00:31<00:05,  3.76it/s]\u001b[A\n",
            " 83%|████████▎ | 104/125 [00:31<00:05,  4.15it/s]\u001b[A\n",
            " 83%|████████▎ | 104/125 [00:31<00:05,  4.15it/s]\u001b[A\n",
            " 84%|████████▍ | 105/125 [00:31<00:04,  4.04it/s]\u001b[A\n",
            " 85%|████████▍ | 106/125 [00:31<00:04,  4.05it/s]\u001b[A\n",
            " 86%|████████▋ | 108/125 [00:31<00:02,  6.49it/s]\u001b[A\n",
            " 87%|████████▋ | 109/125 [00:31<00:02,  6.49it/s]\u001b[A\n",
            " 89%|████████▉ | 111/125 [00:32<00:02,  5.74it/s]\u001b[A\n",
            " 90%|████████▉ | 112/125 [00:32<00:02,  5.77it/s]\u001b[A\n",
            " 90%|█████████ | 113/125 [00:32<00:02,  5.59it/s]\u001b[A\n",
            " 91%|█████████ | 114/125 [00:33<00:02,  3.75it/s]\u001b[A\n",
            " 92%|█████████▏| 115/125 [00:33<00:03,  3.17it/s]\u001b[A\n",
            " 93%|█████████▎| 116/125 [00:33<00:02,  3.03it/s]\u001b[A\n",
            " 94%|█████████▎| 117/125 [00:34<00:02,  3.28it/s]\u001b[A\n",
            " 94%|█████████▍| 118/125 [00:34<00:02,  2.83it/s]\u001b[A\n",
            " 96%|█████████▌| 120/125 [00:35<00:01,  3.52it/s]\u001b[A\n",
            " 98%|█████████▊| 122/125 [00:35<00:00,  4.33it/s]\u001b[A\n",
            " 99%|█████████▉| 124/125 [00:35<00:00,  5.91it/s]\u001b[A\n",
            "100%|██████████| 125/125 [00:36<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [성공] '.pdf' 로딩 (1748개 조각).\n",
            "\n",
            "  '.xlsx' 확장자 로딩 (/content/drive/MyDrive/nomu_dataset3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [정보] '.xlsx' 파일 없음.\n",
            "\n",
            "  '.xls' 확장자 로딩 (/content/drive/MyDrive/nomu_dataset3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [정보] '.xls' 파일 없음.\n",
            "\n",
            "  '.csv' 확장자 로딩 (/content/drive/MyDrive/nomu_dataset3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [정보] '.csv' 파일 없음.\n",
            "\n",
            "  '.txt' 확장자 로딩 (/content/drive/MyDrive/nomu_dataset3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [정보] '.txt' 파일 없음.\n",
            "\n",
            "--- 최종 로드된 문서 조각 수: 1837 ---\n",
            "\n",
            "--- 로드된 문서 타입별 개수 ---\n",
            "  - google_sheet: 89개 조각\n",
            "  - pdf: 1748개 조각\n",
            "\n",
            "--- 첫 로드 문서 샘플 ---\n",
            "  타입: google_sheet\n",
            "  메타데이터: {'source': 'https://docs.google.com/spreadsheets/d/1QeMvmrcYe6QQ8L1n6o1NQ7ASTPafmzdbuDAAKXFCu3k/edit?gid=0', 'title': 'filtered_qa_dataset - Sheet1', 'row': 1, 'file_type': 'google_sheet'}\n",
            "  내용(200자): No.: 0\n",
            "question: 근로계약이 미성년자에게 불리하다고 인정되는 경우 미성년후견인은 그 계약을 해지할 수 있나요?\n",
            "answer: 네. 근로계약을 해지할 수 있습니다.\n",
            "ground_truths: [\"「근로기준법」 제67조 제2항은 친권자,후견인 또는 고용노동부장관은 근로계약이 미성년자에게 불리하다고 인정하는 경우에는 이를 해지할 수 있다.\"라고 규정...\n",
            "\n",
            "--- 단계 4: 데이터 로딩 완료 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === 단계 4: 데이터 로딩  ===\n",
        "\n",
        "print(\"\\n--- 단계 4: 데이터 로딩 시작 ---\")\n",
        "\n",
        "loaded_documents = []\n",
        "loading_errors = {}\n",
        "\n",
        "# --- 4.1. Google Sheets 로딩 ---\n",
        "print(\"\\n--- 4.1 Google Sheets 파일 로딩 ---\")\n",
        "if not target_folder_id or \"YOUR_\" in target_folder_id:\n",
        "    print(\"  ⚠️ 경고: Google Drive 폴더 ID가 유효하지 않아 Google Sheet 로딩 건너<0xEB><0x9A><A9>니다.\")\n",
        "elif not DRIVE_MOUNTED:\n",
        "     print(\"  ⚠️ 경고: Google Drive가 마운트되지 않아 Google Sheet 로딩 건너<0xEB><0x9A><A9>니다.\")\n",
        "else:\n",
        "    try:\n",
        "        gsheet_loader = GoogleDriveLoader(folder_id=target_folder_id, file_types=[\"sheet\"], recursive=True)\n",
        "        print(f\"  GoogleDriveLoader로 폴더 '{target_folder_id}' 로딩 중...\")\n",
        "        gsheet_docs = gsheet_loader.load()\n",
        "        if gsheet_docs:\n",
        "            print(f\"  [성공] Google Sheets 로딩 ({len(gsheet_docs)}개 조각).\")\n",
        "            for doc in gsheet_docs:\n",
        "                doc.metadata['file_type'] = 'google_sheet'\n",
        "                if 'source' not in doc.metadata and 'id' in doc.metadata:\n",
        "                    doc.metadata['source'] = f\"https://docs.google.com/spreadsheets/d/{doc.metadata['id']}\"\n",
        "            loaded_documents.extend(gsheet_docs)\n",
        "        else: print(\"  [정보] 해당 폴더에 Google Sheets 파일 없음.\")\n",
        "    except ImportError as ie: print(f\"  ❌ 임포트 오류: {ie}. 관련 라이브러리 설치 필요.\"); loading_errors['google_sheets'] = str(ie)\n",
        "    except Exception as e: error_msg = f\"{type(e).__name__}: {e}\"; print(f\"  ❌ 로딩 오류: {error_msg}\"); loading_errors['google_sheets'] = error_msg\n",
        "\n",
        "# --- 4.2. 다른 파일 형식 로딩 (PDF, Excel, CSV, TXT 등) ---\n",
        "print(\"\\n--- 4.2 다른 파일 형식 로딩 (DirectoryLoader) ---\")\n",
        "if not DRIVE_MOUNTED and not os.path.exists(base_folder_path):\n",
        "    print(f\"  ⚠️ 경고: Drive 미마운트 및 로컬 경로({base_folder_path}) 없음. 파일 로딩 건너<0xEB><0x9A><A9>니다.\")\n",
        "else:\n",
        "    LOADER_MAPPING = { \".pdf\": (PyPDFLoader, {}), \".xlsx\": (UnstructuredExcelLoader, {\"mode\": \"single\"}), \".xls\": (UnstructuredExcelLoader, {\"mode\": \"single\"}), \".csv\": (CSVLoader, {\"encoding\": \"utf-8\"}), \".txt\": (UnstructuredFileLoader, {}) }\n",
        "    supported_extensions = list(LOADER_MAPPING.keys())\n",
        "    for ext in supported_extensions:\n",
        "        print(f\"\\n  '{ext}' 확장자 로딩 ({base_folder_path})...\")\n",
        "        loader_cls, loader_args = LOADER_MAPPING[ext]\n",
        "        try:\n",
        "            loader = DirectoryLoader( base_folder_path, glob=f\"**/*{ext}\", loader_cls=loader_cls, loader_kwargs=loader_args, recursive=True, show_progress=True, use_multithreading=True, silent_errors=False )\n",
        "            docs = loader.load()\n",
        "            if docs:\n",
        "                print(f\"    [성공] '{ext}' 로딩 ({len(docs)}개 조각).\")\n",
        "                for doc in docs: doc.metadata['file_type'] = ext.lstrip('.')\n",
        "                loaded_documents.extend(docs)\n",
        "            else: print(f\"    [정보] '{ext}' 파일 없음.\")\n",
        "        except ImportError as ie: error_msg = f\"{ie}\"; print(f\"    ❌ 임포트 오류: {error_msg}\"); loading_errors[f'loader_{ext}'] = f\"ImportError: {error_msg}\"\n",
        "        except Exception as e: error_msg = f\"{type(e).__name__}: {e}\"; print(f\"    ❌ 로딩 오류: {error_msg}\"); loading_errors[f'loader_{ext}'] = error_msg\n",
        "\n",
        "# --- 4.3. 로딩 결과 요약 ---\n",
        "print(f\"\\n--- 최종 로드된 문서 조각 수: {len(loaded_documents)} ---\")\n",
        "doc_type_counts = {}\n",
        "for doc in loaded_documents: file_type = doc.metadata.get('file_type', 'unknown'); doc_type_counts[file_type] = doc_type_counts.get(file_type, 0) + 1\n",
        "print(\"\\n--- 로드된 문서 타입별 개수 ---\");\n",
        "if doc_type_counts: [print(f\"  - {f_type}: {count}개 조각\") for f_type, count in sorted(doc_type_counts.items())]\n",
        "else: print(\"  로드된 문서 없음.\")\n",
        "if loading_errors: print(\"\\n--- 로딩 오류 요약 ---\"); [print(f\"  - {src}: {err}\") for src, err in loading_errors.items()]\n",
        "if loaded_documents:\n",
        "    print(\"\\n--- 첫 로드 문서 샘플 ---\")\n",
        "    try: first_doc = loaded_documents[0]; print(f\"  타입: {first_doc.metadata.get('file_type')}\\n  메타데이터: {first_doc.metadata}\\n  내용(200자): {first_doc.page_content[:200]}...\")\n",
        "    except Exception as e: print(f\"  !! 샘플 출력 오류: {e}\")\n",
        "else: print(\"\\n로드된 문서 없음. 경로, 파일 형식, 권한 확인 필요.\")\n",
        "print(\"\\n--- 단계 4: 데이터 로딩 완료 ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L27LiqhHrCtN"
      },
      "source": [
        "# 5: 텍스트 분할 (Chunking, 패턴 기반 + 길이 제한)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0i8Q1-QBAS7"
      },
      "source": [
        "형사처벌/벌금/과태료 등 중요한 조항을 청크로 정확히 보존하고, fallback 분할도 완화하며, 검증용 로그도 포함한 전체 청킹 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0b-iOrmKpHP"
      },
      "source": [
        "형사처벌 조항 regex 선별 추가 포함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "979crxyML9kh"
      },
      "source": [
        "✅ 형사처벌 관련 조항을 우선적으로 정규식 기반으로 추출하여 단독 청크로 분리했습니다.\n",
        "\n",
        "✅ 중복 삽입 방지를 위해 already_added_chunks 집합을 사용했습니다.\n",
        "\n",
        "✅ 기존 \"제X조\" 기반 청킹에서 중복 조항 추가를 방지하도록 조건 추가했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ccQuIgLzYX",
        "outputId": "1b27dec7-16dd-44f6-bf57-1f319158f0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 5: 텍스트 분할 시작 (형사처벌 조항 우선 보존 + 중복 방지 적용) ---\n",
            "[정보] 패턴 기반 청킹 시도 (법령 PDF 대상). 기준 크기=500, 중첩=100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "문서 청킹 중:   0%|          | 0/1837 [00:00<?, ?it/s]\u001b[A\n",
            "문서 청킹 중:  39%|███▉      | 722/1837 [00:00<00:00, 7195.41it/s]\u001b[A\n",
            "문서 청킹 중: 100%|██████████| 1837/1837 [00:00<00:00, 7092.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[성공] 총 1837개 문서 → 8854개 청크 분할 완료.\n",
            "\n",
            "[검증] '형사/과태료/벌금' 포함 청크 수: 498\n",
            "\n",
            "샘플 청크:\n",
            "No.: 0\n",
            "question: 근로계약이 미성년자에게 불리하다고 인정되는 경우 미성년후견인은 그 계약을 해지할 수 있나요?\n",
            "answer: 네. 근로계약을 해지할 수 있습니다.\n",
            "ground_truths: [\"「근로기준법」 제67조 제2항은 친권자,후견인 또는 고용노동부장관은 근로계약이 미성년자에게 불리하다고 인정하는 경우에는 이를 해지할 수 있다.\"라고 규정...\n",
            "메타데이터: {'source': 'https://docs.google.com/spreadsheets/d/1QeMvmrcYe6QQ8L1n6o1NQ7ASTPafmzdbuDAAKXFCu3k/edit?gid=0', 'title': 'filtered_qa_dataset - Sheet1', 'row': 1, 'file_type': 'google_sheet'}\n",
            "--- 단계 5: 텍스트 분할 완료 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\n--- 단계 5: 텍스트 분할 시작 (형사처벌 조항 우선 보존 + 중복 방지 적용) ---\")\n",
        "\n",
        "# 설정값\n",
        "chunk_size_setting = 500\n",
        "chunk_overlap_setting = 100\n",
        "\n",
        "# 제재 관련 중요 키워드\n",
        "important_keywords = [\"형사\", \"벌금\", \"과태료\", \"처벌\"]\n",
        "\n",
        "# fallback용 스플리터\n",
        "fallback_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "split_texts = []\n",
        "already_added_chunks = set()  # ✅ 중복 방지용 집합\n",
        "\n",
        "if 'loaded_documents' in locals() and loaded_documents:\n",
        "    print(f\"[정보] 패턴 기반 청킹 시도 (법령 PDF 대상). 기준 크기={chunk_size_setting}, 중첩={chunk_overlap_setting}\")\n",
        "    processed_docs_count = 0\n",
        "    skipped_docs_count = 0\n",
        "\n",
        "    for doc in tqdm(loaded_documents, desc=\"문서 청킹 중\"):\n",
        "        doc_content = doc.page_content\n",
        "        doc_metadata = doc.metadata\n",
        "        file_type = doc_metadata.get('file_type', 'unknown')\n",
        "\n",
        "        if file_type != 'pdf' or not doc_content.strip():\n",
        "            if doc_content.strip():\n",
        "                try:\n",
        "                    sub_chunks = fallback_splitter.split_text(doc_content)\n",
        "                    for chunk_text in sub_chunks:\n",
        "                        split_texts.append(Document(page_content=chunk_text, metadata=doc_metadata.copy()))\n",
        "                    processed_docs_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n!! 기본 분할 오류 (타입: {file_type}, 소스: {doc_metadata.get('source', 'N/A')}): {e}\")\n",
        "                    skipped_docs_count += 1\n",
        "            else:\n",
        "                skipped_docs_count += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # ✅ Step 1: 형사처벌 조항을 정규식으로 찾아 단독 청크로 우선 보존\n",
        "            penalty_matches = re.findall(r'(제\\s?\\d+\\s?조.*?(형사|벌금|과태료|처벌)[^제]{0,500})', doc_content)\n",
        "            for match in penalty_matches:\n",
        "                matched_text = match[0].strip()\n",
        "                if matched_text not in already_added_chunks:\n",
        "                    split_texts.append(Document(page_content=matched_text, metadata=doc_metadata.copy()))\n",
        "                    already_added_chunks.add(matched_text)\n",
        "\n",
        "            # Step 2: \"제X조\" 단위로 분할하여 일반 조항 처리\n",
        "            preliminary_chunks_with_title = re.split(r'(제\\s?\\d+\\s?조)', doc_content)\n",
        "            current_chunk_content = \"\"\n",
        "            if preliminary_chunks_with_title[0].strip():\n",
        "                current_chunk_content = preliminary_chunks_with_title[0].strip()\n",
        "\n",
        "            for i in range(1, len(preliminary_chunks_with_title), 2):\n",
        "                title = preliminary_chunks_with_title[i]\n",
        "                content = preliminary_chunks_with_title[i+1] if (i+1) < len(preliminary_chunks_with_title) else \"\"\n",
        "                article_block = title + content\n",
        "\n",
        "                # ✅ 형사/과태료/벌금 포함된 조항은 이미 추가된 경우 제외\n",
        "                if any(kw in article_block for kw in important_keywords):\n",
        "                    if article_block.strip() not in already_added_chunks:\n",
        "                        split_texts.append(Document(page_content=article_block.strip(), metadata=doc_metadata.copy()))\n",
        "                        already_added_chunks.add(article_block.strip())\n",
        "                    current_chunk_content = \"\"\n",
        "                    continue\n",
        "\n",
        "                if current_chunk_content and (len(current_chunk_content) + len(article_block) <= chunk_size_setting):\n",
        "                    current_chunk_content += \"\\n\\n\" + article_block\n",
        "                else:\n",
        "                    if current_chunk_content:\n",
        "                        if len(current_chunk_content) > chunk_size_setting:\n",
        "                            sub_chunks = fallback_splitter.split_text(current_chunk_content)\n",
        "                            for chunk_text in sub_chunks:\n",
        "                                split_texts.append(Document(page_content=chunk_text, metadata=doc_metadata.copy()))\n",
        "                        else:\n",
        "                            split_texts.append(Document(page_content=current_chunk_content, metadata=doc_metadata.copy()))\n",
        "                    current_chunk_content = article_block.strip()\n",
        "\n",
        "            if current_chunk_content:\n",
        "                if len(current_chunk_content) > chunk_size_setting:\n",
        "                    sub_chunks = fallback_splitter.split_text(current_chunk_content)\n",
        "                    for chunk_text in sub_chunks:\n",
        "                        split_texts.append(Document(page_content=chunk_text, metadata=doc_metadata.copy()))\n",
        "                else:\n",
        "                    split_texts.append(Document(page_content=current_chunk_content, metadata=doc_metadata.copy()))\n",
        "\n",
        "            processed_docs_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n!! 패턴 기반 분할 오류 (소스: {doc_metadata.get('source', 'N/A')}): {e}\")\n",
        "            try:\n",
        "                sub_chunks = fallback_splitter.split_text(doc_content)\n",
        "                for chunk_text in sub_chunks:\n",
        "                    split_texts.append(Document(page_content=chunk_text, metadata=doc_metadata.copy()))\n",
        "                print(\"  -> 오류 발생하여 fallback 방식으로 처리함.\")\n",
        "                processed_docs_count += 1\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"  -> fallback 방식도 실패: {fallback_e}\")\n",
        "                skipped_docs_count += 1\n",
        "\n",
        "    print(f\"\\n[성공] 총 {processed_docs_count}개 문서 → {len(split_texts)}개 청크 분할 완료.\")\n",
        "    if skipped_docs_count > 0:\n",
        "        print(f\"[경고] {skipped_docs_count}개 문서 처리 실패.\")\n",
        "\n",
        "    penalty_chunks = [c for c in split_texts if any(kw in c.page_content for kw in important_keywords)]\n",
        "    print(f\"\\n[검증] '형사/과태료/벌금' 포함 청크 수: {len(penalty_chunks)}\")\n",
        "\n",
        "    if split_texts:\n",
        "        print(f\"\\n샘플 청크:\\n{split_texts[0].page_content[:200]}...\")\n",
        "        print(f\"메타데이터: {split_texts[0].metadata}\")\n",
        "else:\n",
        "    print(\"!! 분할할 문서가 없습니다.\")\n",
        "\n",
        "print(\"--- 단계 5: 텍스트 분할 완료 ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV5uvWcnV4jy"
      },
      "source": [
        "# 수집된 청크 검사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q49w4TBC4yds"
      },
      "outputs": [],
      "source": [
        "penalty_chunks = [c for c in split_texts if \"제37조\" in c.page_content or \"300만 원\" in c.page_content]\n",
        "for i, c in enumerate(penalty_chunks):\n",
        "    print(f\"\\n[형사처벌 청크 {i+1}]:\\n{c.page_content[:500]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbxJAJcwr6Uk"
      },
      "source": [
        "# 6: 임베딩 모델 설정 (OpenAI: text-embedding-3-large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moF9urGCjHfO",
        "outputId": "fb91ddeb-7557-4367-dd95-d890aee64077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 6: 임베딩 모델 설정 시작 (OpenAI: text-embedding-3-large) ---\n",
            "[정보] langchain_openai.OpenAIEmbeddings 임포트 확인.\n",
            "[정보] OpenAI 임베딩 모델 (text-embedding-3-large) 설정 시도...\n",
            "[정보] 단계 2에서 설정된 OPENAI_API_KEY 환경 변수를 사용합니다.\n",
            "[정보] 임베딩 모델 테스트 중 (OpenAI API 호출)...\n",
            "[성공] OpenAI 임베딩 모델 (text-embedding-3-large) 설정 및 테스트 완료.\n",
            "--- 단계 6: 임베딩 모델 설정 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 6: 임베딩 모델 설정 (OpenAI: text-embedding-3-large) ===\n",
        "print(\"\\n--- 단계 6: 임베딩 모델 설정 시작 (OpenAI: text-embedding-3-large) ---\") # <<< 모델 이름 변경\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "try:\n",
        "    # OpenAI 임베딩을 위한 클래스 임포트\n",
        "    # pip install -U langchain-openai  <-- 먼저 이 패키지를 설치해야 합니다.\n",
        "    from langchain_openai import OpenAIEmbeddings\n",
        "    print(\"[정보] langchain_openai.OpenAIEmbeddings 임포트 확인.\")\n",
        "except ImportError as e:\n",
        "    print(f\"!! [오류] 필요한 라이브러리 임포트 실패: {e}\")\n",
        "    print(\"   langchain-openai, openai 패키지가 설치되었는지 확인하세요.\")\n",
        "    # 필요한 클래스가 없으면 이후 진행 불가\n",
        "    OpenAIEmbeddings = None\n",
        "\n",
        "embeddings = None # 최종 임베딩 객체 변수 초기화\n",
        "\n",
        "if OpenAIEmbeddings: # 라이브러리 임포트 성공 시 진행\n",
        "    try:\n",
        "        # 사용할 OpenAI 모델 지정 (text-embedding-3-large로 변경)\n",
        "        openai_model_name = \"text-embedding-3-large\" # <<< 모델 이름 변경 (여기를 수정했습니다)\n",
        "        print(f\"[정보] OpenAI 임베딩 모델 ({openai_model_name}) 설정 시도...\")\n",
        "        print(\"[정보] 단계 2에서 설정된 OPENAI_API_KEY 환경 변수를 사용합니다.\")\n",
        "\n",
        "        # <<< OpenAIEmbeddings 클래스 사용 (API 키 자동 감지) >>>\n",
        "        # 단계 2에서 os.environ[\"OPENAI_API_KEY\"] 가 설정되었으므로,\n",
        "        # API 키를 명시적으로 전달할 필요 없이 자동으로 사용됩니다.\n",
        "        embeddings = OpenAIEmbeddings(\n",
        "            model=openai_model_name # 수정된 모델 이름 사용\n",
        "            # openai_api_key 파라미터 생략\n",
        "            # text-embedding-3-large는 기본 차원(3072) 외에\n",
        "            # 다른 차원(e.g., 1536, 512)을 지정할 수 있습니다. 필요시 dimensions 파라미터 추가.\n",
        "            # 예: dimensions=1536\n",
        "        )\n",
        "        # ------------------------------------------------------\n",
        "\n",
        "        # 간단한 테스트 (API 키 유효성 및 통신 확인)\n",
        "        print(\"[정보] 임베딩 모델 테스트 중 (OpenAI API 호출)...\")\n",
        "        _ = embeddings.embed_query(\"테스트 문장입니다.\")\n",
        "        print(f\"[성공] OpenAI 임베딩 모델 ({openai_model_name}) 설정 및 테스트 완료.\") # <<< 출력 메시지 변경 (변수 사용으로 자동 반영)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!! [오류] OpenAI 임베딩 모델 ({openai_model_name}) 설정 실패: {e}\") # <<< 출력 메시지 변경 (변수 사용으로 자동 반영)\n",
        "        print(\"   - 단계 2에서 OpenAI API 키가 올바르게 설정되었는지 확인하세요.\")\n",
        "        print(\"   - OpenAI API 키 자체의 유효성 및 할당량(quota)을 확인하세요.\")\n",
        "        print(\"   - 인터넷 연결 상태 및 OpenAI 서비스 상태를 확인하세요.\")\n",
        "        print(\"   - 관련 라이브러리(langchain-openai, openai) 설치 및 호환성을 확인하세요.\")\n",
        "        # text-embedding-3-large 모델 접근 권한이 계정에 있는지 확인 필요할 수 있음\n",
        "        embeddings = None # 실패 시 None으로 설정\n",
        "else:\n",
        "    print(\"!! 필요한 라이브러리(OpenAIEmbeddings) 임포트 실패. 임베딩 모델 설정 불가.\")\n",
        "\n",
        "print(\"--- 단계 6: 임베딩 모델 설정 완료 ---\")\n",
        "\n",
        "# OpenAI 모델은 외부 API를 사용하므로 로컬 GPU/CPU 확인은 불필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dWM7T_R4ZIF"
      },
      "source": [
        "# 7: Vector Store 구축 (FAISS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvIY_g-74WB4"
      },
      "source": [
        "--- 경로 설정 ---\n",
        "📂 결과 저장 경로: /content/drive/MyDrive/nomu_rag_result\n",
        "  - 상태 파일: /content/drive/MyDrive/nomu_rag_result/vectorstore_build_status.json\n",
        "  - 체크포인트 폴더 (FAISS): /content/drive/MyDrive/nomu_rag_result/faiss_index_nomu_checkpoint\n",
        "  - 최종 인덱스 폴더 (FAISS): /content/drive/MyDrive/nomu_rag_result/faiss_index_nomu_final\n",
        "  - BM25용 데이터 파일: /content/drive/MyDrive/nomu_rag_result/split_texts_for_bm25.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo8-0rLR3ncZ",
        "outputId": "ae87fa6c-ae0b-42bd-810c-22ff5dc90682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 7: Vector Store 구축 및 BM25 데이터 저장 시작 ---\n",
            "\n",
            "--- 7.1: 설정 및 입력 변수 확인 ---\n",
            "✅ 입력 확인: 총 8854개 청크 및 임베딩 모델 확인됨.\n",
            "\n",
            "--- 7.2: 경로 설정 ---\n",
            "📂 결과 저장 경로: /content/drive/MyDrive/nomu_rag_result\n",
            "  - 상태 파일: /content/drive/MyDrive/nomu_rag_result/vectorstore_build_status.json\n",
            "  - 체크포인트 폴더 (FAISS): /content/drive/MyDrive/nomu_rag_result/faiss_index_nomu_checkpoint\n",
            "  - 최종 인덱스 폴더 (FAISS): /content/drive/MyDrive/nomu_rag_result/faiss_index_nomu_final\n",
            "  - BM25용 데이터 파일: /content/drive/MyDrive/nomu_rag_result/split_texts_for_bm25.pkl\n",
            "\n",
            "--- 7.3: 장치 확인 ---\n",
            "ℹ️ 사용할 장치: cpu\n",
            "⚠️ 경고: GPU 사용 불가. 시간 소요 예상.\n",
            "\n",
            "--- 7.4: 이전 작업 상태 및 체크포인트 로드 ---\n",
            "  - 상태 로드 완료. 마지막 인덱스: 8853\n",
            "  - 체크포인트 인덱스 로딩: /content/drive/MyDrive/nomu_rag_result/faiss_index_nomu_checkpoint\n",
            "  - FAISS 체크포인트 로드 완료. 8854 벡터 포함.\n",
            "  ✅ 이전 FAISS 작업 완료됨.\n",
            "\n",
            "✅ FAISS Vector Store 구축 작업이 이미 완료된 상태입니다.\n",
            "\n",
            "--- 단계 7: Vector Store 처리 및 BM25 데이터 저장 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# === 단계 7: Vector Store 구축 (FAISS) 및 BM25용 데이터 저장 ===\n",
        "# 체크포인팅 방식을 save_local로 변경\n",
        "\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "# import pickle # pickle은 BM25 데이터 저장에만 사용\n",
        "import torch\n",
        "import traceback\n",
        "from tqdm.auto import tqdm\n",
        "# LangChain 관련 임포트 확인\n",
        "if 'FAISS' not in locals() or 'Document' not in locals():\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "    from langchain_core.documents import Document\n",
        "    print(\"⚠️ FAISS 또는 Document 클래스 재임포트됨.\")\n",
        "if 'HuggingFaceEmbeddings' not in locals() and 'GoogleGenerativeAIEmbeddings' not in locals():\n",
        "    # 사용 중인 임베딩 클래스를 임포트해야 합니다.\n",
        "    from langchain_community.embeddings import HuggingFaceEmbeddings # 예시\n",
        "    # from langchain_google_genai import GoogleGenerativeAIEmbeddings # 예시\n",
        "    print(\"⚠️ 임베딩 클래스 재임포트됨.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- 단계 7: Vector Store 구축 및 BM25 데이터 저장 시작 ---\")\n",
        "\n",
        "# --- 7.1: 설정 및 입력 변수 확인 ---\n",
        "print(\"\\n--- 7.1: 설정 및 입력 변수 확인 ---\")\n",
        "vectorstore = None\n",
        "batch_size = 500 # 배치 크기 확인\n",
        "sleep_time = 5\n",
        "max_retries = 3\n",
        "total_chunks = 0\n",
        "start_index = 0\n",
        "loaded_from_checkpoint = False\n",
        "\n",
        "if 'split_texts' not in locals() or not isinstance(split_texts, list) or not split_texts: print(\"!! 오류: 'split_texts' 없음. 중단.\"); exit()\n",
        "elif 'embeddings' not in locals() or embeddings is None: print(\"!! 오류: 'embeddings' 없음. 중단.\"); exit()\n",
        "else: total_chunks = len(split_texts); print(f\"✅ 입력 확인: 총 {total_chunks}개 청크 및 임베딩 모델 확인됨.\")\n",
        "\n",
        "# --- 7.2: 경로 설정 및 디렉토리 생성 ---\n",
        "print(\"\\n--- 7.2: 경로 설정 ---\")\n",
        "if 'result_dir' not in locals() or not result_dir: result_dir = \"/content/drive/MyDrive/nomu_rag_result\"; print(f\"⚠️ result_dir 변수 없어 기본 경로 설정: {result_dir}\"); os.makedirs(result_dir, exist_ok=True)\n",
        "else: print(f\"📂 결과 저장 경로: {result_dir}\"); os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "vs_status_file = os.path.join(result_dir, \"vectorstore_build_status.json\")\n",
        "# <<< 체크포인트 경로를 폴더로 변경 (save_local 사용) >>>\n",
        "vs_checkpoint_path = os.path.join(result_dir, \"faiss_index_nomu_checkpoint\") # .pkl 대신 폴더명\n",
        "vs_final_save_path = os.path.join(result_dir, \"faiss_index_nomu_final\")\n",
        "bm25_data_save_path = os.path.join(result_dir, \"split_texts_for_bm25.pkl\")\n",
        "\n",
        "print(f\"  - 상태 파일: {vs_status_file}\")\n",
        "print(f\"  - 체크포인트 폴더 (FAISS): {vs_checkpoint_path}\") # <<< 이름 변경\n",
        "print(f\"  - 최종 인덱스 폴더 (FAISS): {vs_final_save_path}\")\n",
        "print(f\"  - BM25용 데이터 파일: {bm25_data_save_path}\")\n",
        "\n",
        "# --- 7.3: GPU 확인 --- (이전과 동일)\n",
        "print(\"\\n--- 7.3: 장치 확인 ---\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'; print(f\"ℹ️ 사용할 장치: {device}\");\n",
        "if device == 'cpu': print(\"⚠️ 경고: GPU 사용 불가. 시간 소요 예상.\")\n",
        "\n",
        "# --- 7.4: 이전 작업 상태 및 체크포인트 로드 ---\n",
        "if total_chunks > 0:\n",
        "    print(\"\\n--- 7.4: 이전 작업 상태 및 체크포인트 로드 ---\")\n",
        "    try:\n",
        "        # <<< 체크포인트 파일 대신 폴더 존재 여부 확인 >>>\n",
        "        if os.path.exists(vs_status_file) and os.path.isdir(vs_checkpoint_path):\n",
        "            with open(vs_status_file, 'r') as f_status: status_data = json.load(f_status); last_processed_index = status_data.get('last_processed_index', -1); start_index = last_processed_index + 1; print(f\"  - 상태 로드 완료. 마지막 인덱스: {last_processed_index}\")\n",
        "\n",
        "            # <<< pickle.load 대신 FAISS.load_local 사용 >>>\n",
        "            print(f\"  - 체크포인트 인덱스 로딩: {vs_checkpoint_path}\")\n",
        "            if 'embeddings' in locals() and embeddings:\n",
        "                vectorstore = FAISS.load_local(\n",
        "                    folder_path=vs_checkpoint_path,\n",
        "                    embeddings=embeddings,\n",
        "                    allow_dangerous_deserialization=True # 신뢰할 수 있는 소스일 때만\n",
        "                )\n",
        "                print(f\"  - FAISS 체크포인트 로드 완료. {vectorstore.index.ntotal} 벡터 포함.\")\n",
        "                loaded_from_checkpoint = True\n",
        "            else:\n",
        "                print(\"  !! 오류: 임베딩 함수('embeddings')가 없어 체크포인트를 로드할 수 없음. 처음부터 시작.\")\n",
        "                vectorstore = None; start_index = 0; loaded_from_checkpoint = False\n",
        "\n",
        "            if start_index >= total_chunks: print(\"  ✅ 이전 FAISS 작업 완료됨.\")\n",
        "            elif loaded_from_checkpoint: print(f\"  ▶️ {start_index}번 인덱스부터 FAISS 작업 재개.\")\n",
        "            # else 블록은 위에서 처리됨\n",
        "\n",
        "        else: print(f\"  - 이전 상태 파일 또는 체크포인트 폴더 없음. 처음부터 시작.\"); vectorstore = None; start_index = 0\n",
        "    except Exception as e: print(f\"  ⚠️ 상태/체크포인트 로드 오류: {e}. 처음부터 시작.\"); traceback.print_exc(); vectorstore = None; start_index = 0\n",
        "else: print(\"ℹ️ 처리할 청크 없음.\")\n",
        "\n",
        "# --- 7.5: FAISS Vector Store 구축 ---\n",
        "if total_chunks > 0 and start_index < total_chunks:\n",
        "    print(f\"\\n--- 7.5: FAISS 인덱스 구축 시작 (총 {total_chunks} 중 {start_index}부터, 배치 {batch_size}) ---\")\n",
        "    all_processed_successfully = True\n",
        "    try:\n",
        "        progress_bar = tqdm(range(start_index, total_chunks, batch_size), initial=start_index // batch_size, total=-(total_chunks // -batch_size), desc=\"FAISS 구축 중\")\n",
        "        for i in progress_bar:\n",
        "            batch_start_idx = i; batch_end_idx = min(i + batch_size, total_chunks); batch_docs = split_texts[batch_start_idx:batch_end_idx]\n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    if i == start_index and not loaded_from_checkpoint:\n",
        "                        progress_bar.set_description(f\"첫 배치({batch_start_idx}-{batch_end_idx-1}) 생성 중\")\n",
        "                        vectorstore = FAISS.from_documents(batch_docs, embeddings)\n",
        "                        print(f\"\\n   - 첫 배치 FAISS 생성 완료 (벡터 {vectorstore.index.ntotal}개)\")\n",
        "                    elif vectorstore is not None:\n",
        "                        progress_bar.set_description(f\"배치({batch_start_idx}-{batch_end_idx-1}) 추가 중\")\n",
        "                        vectorstore.add_documents(batch_docs)\n",
        "                        print(f\"\\n   - 배치 FAISS 추가 완료 (총 벡터 {vectorstore.index.ntotal}개)\")\n",
        "                    else: raise ValueError(\"Vectorstore 객체 None 상태.\")\n",
        "\n",
        "                    current_processed_index = batch_end_idx - 1\n",
        "                    try:\n",
        "                        # <<< 체크포인팅: 상태 저장 후 save_local 호출 >>>\n",
        "                        with open(vs_status_file, 'w') as f_status: json.dump({'last_processed_index': current_processed_index}, f_status)\n",
        "                        # 체크포인트 폴더에 덮어쓰기 (이전 파일 삭제됨)\n",
        "                        vectorstore.save_local(vs_checkpoint_path)\n",
        "                        # print(f\"  💾 체크포인트 저장 완료 (폴더: {vs_checkpoint_path}, 인덱스: {current_processed_index})\")\n",
        "                    except Exception as e_save: print(f\"  ⚠️ 진행 상황(체크포인트) 저장 실패: {e_save}\")\n",
        "                    break # 성공 시 재시도 루프 탈출\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n!! 배치 처리 오류 (시도 {attempt+1}/{max_retries}): {type(e).__name__} - {e}\")\n",
        "                    traceback.print_exc()\n",
        "                    if attempt < max_retries - 1: wait_time = sleep_time * (attempt + 2); progress_bar.set_description(f\"오류, {wait_time}초 후 재시도...\"); print(f\"  ... {wait_time}초 후 재시도 ...\"); time.sleep(wait_time)\n",
        "                    else: print(\"!! 최대 재시도 초과. 구축 중단.\"); all_processed_successfully = False; raise RuntimeError(f\"최대 재시도 실패: {e}\")\n",
        "            if not all_processed_successfully: break\n",
        "            if batch_end_idx < total_chunks: time.sleep(sleep_time) # API Rate Limit\n",
        "\n",
        "        # --- 루프 완료 후 최종 처리 ---\n",
        "        if all_processed_successfully:\n",
        "            print(\"\\n[성공] 모든 FAISS 배치 처리 완료.\")\n",
        "            # --- 6.6: 최종 결과 저장 ---\n",
        "            print(\"\\n--- 6.6: 최종 결과 저장 ---\")\n",
        "            # 1. 최종 FAISS 인덱스 저장 (save_local)\n",
        "            print(f\"💾 최종 FAISS 인덱스 저장: {vs_final_save_path}\")\n",
        "            try:\n",
        "                if vectorstore: vectorstore.save_local(vs_final_save_path); print(f\"✅ 최종 FAISS 인덱스 저장 완료.\")\n",
        "                else: print(\"⚠️ 최종 저장 시 VectorStore 객체 없음.\")\n",
        "            except Exception as e: print(f\"❌ 최종 FAISS 인덱스 저장 오류: {e}\"); traceback.print_exc()\n",
        "            # 2. BM25용 데이터 저장 (pickle)\n",
        "            print(f\"💾 BM25용 텍스트 데이터 저장: {bm25_data_save_path}\")\n",
        "            try:\n",
        "                if 'split_texts' in locals() and split_texts:\n",
        "                    # <<< pickle 임포트 확인 >>>\n",
        "                    import pickle\n",
        "                    with open(bm25_data_save_path, 'wb') as f_texts: pickle.dump(split_texts, f_texts); print(f\"✅ BM25용 텍스트 데이터 ({len(split_texts)}개 청크) 저장 완료.\")\n",
        "                else: print(\"⚠️ BM25용 데이터('split_texts') 없어 저장 불가.\")\n",
        "            except Exception as e: print(f\"❌ split_texts 저장 실패: {e}\"); traceback.print_exc()\n",
        "            # (선택) 중간 파일 삭제\n",
        "            # try: ... (삭제 로직) ... except ...\n",
        "\n",
        "    except Exception as e_main_loop: print(f\"\\n!! FAISS 구축 실패: {e_main_loop}\"); print(f\"[정보] 마지막 성공 지점 데이터는 '{vs_checkpoint_path}' 폴더에 있을 수 있음.\")\n",
        "\n",
        "# --- 이전 실행에서 이미 완료된 경우 처리 ---\n",
        "elif total_chunks > 0 and start_index >= total_chunks:\n",
        "     print(\"\\n✅ FAISS Vector Store 구축 작업이 이미 완료된 상태입니다.\")\n",
        "     # 완료된 상태에서도 최종 파일들이 존재하는지 확인하고 없으면 저장 시도\n",
        "     # 1. 최종 FAISS 인덱스 확인 및 저장\n",
        "     if not os.path.isdir(vs_final_save_path): # <<< 폴더 존재 여부 확인 >>>\n",
        "         if vectorstore: # 체크포인트에서 로드된 vectorstore가 있다면\n",
        "             print(f\"\\n💾 최종 FAISS 인덱스 폴더 없어 저장 시도: '{vs_final_save_path}'\") # <<< print 문 분리\n",
        "             # <<< try...except 블록을 새 줄에서 시작 >>>\n",
        "             try:\n",
        "                 vectorstore.save_local(vs_final_save_path)\n",
        "                 print(\"✅ 저장 완료.\")\n",
        "             except Exception as e:\n",
        "                 print(f\"❌ 저장 오류: {e}\")\n",
        "                 traceback.print_exc()\n",
        "         else:\n",
        "             print(f\"⚠️ 최종 FAISS 인덱스 폴더 없고, 로드된 vectorstore도 없어 저장 불가.\")\n",
        "\n",
        "     # 2. BM25용 데이터 확인 및 저장\n",
        "     if not os.path.exists(bm25_data_save_path):\n",
        "         if 'split_texts' in locals() and split_texts:\n",
        "             print(f\"\\n💾 BM25용 텍스트 데이터 파일({bm25_data_save_path}) 없어 저장 시도...\") # <<< print 문 분리\n",
        "             # <<< try...except 블록을 새 줄에서 시작 >>>\n",
        "             try:\n",
        "                 # <<< pickle 임포트 확인 (필요시) >>>\n",
        "                 import pickle\n",
        "                 with open(bm25_data_save_path, 'wb') as f:\n",
        "                     pickle.dump(split_texts, f)\n",
        "                 print(\"✅ 저장 완료.\")\n",
        "             except Exception as e:\n",
        "                 print(f\"❌ 저장 실패: {e}\")\n",
        "                 traceback.print_exc()\n",
        "         else:\n",
        "             print(f\"⚠️ BM25용 데이터 파일 없고, split_texts 변수도 없어 저장 불가.\")\n",
        "\n",
        "print(\"\\n--- 단계 7: Vector Store 처리 및 BM25 데이터 저장 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_6r7-WP5Ynw"
      },
      "source": [
        "# 8: Retriever 설정 (하이브리드 검색)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc2RDKm14skp",
        "outputId": "5fc25ed6-02be-4359-8c53-1bad886e74f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 8: Retriever 설정 시작 (하이브리드 검색) ---\n",
            "[정보] 새로 생성된 FAISS VectorStore 사용.\n",
            "[정보] 현재 세션의 split_texts 데이터 사용 (BM25용).\n",
            "- Dense Retriever (FAISS) 설정 완료 (k=4).\n",
            "- Sparse Retriever (BM25) 설정 완료 (k=4).\n",
            "- Ensemble Retriever 설정 완료 (Weights: BM25=0.4, FAISS=0.6).\n",
            "--- 단계 8: Retriever 설정 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 8: Retriever 설정 (하이브리드 검색) ===\n",
        "\n",
        "print(\"\\n--- 단계 8: Retriever 설정 시작 (하이브리드 검색) ---\")\n",
        "\n",
        "# 사용할 VectorStore와 split_texts 결정\n",
        "# 로드 성공 시 로드된 것 사용, 아니면 구축 단계에서 생성된 것 사용\n",
        "final_vectorstore = None\n",
        "final_split_texts = None # BM25용\n",
        "\n",
        "if 'loaded_vectorstore' in locals() and loaded_vectorstore:\n",
        "    final_vectorstore = loaded_vectorstore\n",
        "    print(\"[정보] 로드된 FAISS VectorStore 사용.\")\n",
        "elif 'vectorstore' in locals() and vectorstore:\n",
        "    final_vectorstore = vectorstore\n",
        "    print(\"[정보] 새로 생성된 FAISS VectorStore 사용.\")\n",
        "else:\n",
        "    print(\"!! 오류: 사용 가능한 FAISS VectorStore 객체 없음.\")\n",
        "\n",
        "if 'loaded_split_texts' in locals() and loaded_split_texts:\n",
        "    final_split_texts = loaded_split_texts\n",
        "    print(\"[정보] 로드된 split_texts 데이터 사용 (BM25용).\")\n",
        "elif 'split_texts' in locals() and split_texts:\n",
        "    final_split_texts = split_texts\n",
        "    print(\"[정보] 현재 세션의 split_texts 데이터 사용 (BM25용).\")\n",
        "else:\n",
        "    print(\"!! 오류: BM25용 split_texts 데이터 없음.\")\n",
        "\n",
        "retriever = None # 최종 리트리버 초기화\n",
        "\n",
        "if final_vectorstore:\n",
        "    # Dense Retriever (FAISS)\n",
        "    faiss_retriever = final_vectorstore.as_retriever(search_kwargs={'k': 4})\n",
        "    print(f\"- Dense Retriever (FAISS) 설정 완료 (k={faiss_retriever.search_kwargs.get('k')}).\")\n",
        "\n",
        "    if final_split_texts: # BM25용 데이터가 있을 때만 하이브리드 시도\n",
        "        try:\n",
        "            # Sparse Retriever (BM25)\n",
        "            bm25_retriever = BM25Retriever.from_documents(final_split_texts)\n",
        "            bm25_retriever.k = 4\n",
        "            print(f\"- Sparse Retriever (BM25) 설정 완료 (k={bm25_retriever.k}).\")\n",
        "            # Ensemble Retriever\n",
        "            ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.4, 0.6])\n",
        "            retriever = ensemble_retriever\n",
        "            print(f\"- Ensemble Retriever 설정 완료 (Weights: BM25=0.4, FAISS=0.6).\")\n",
        "        except Exception as e:\n",
        "            print(f\"!! BM25/Ensemble 설정 실패: {e}. Dense Retriever만 사용.\")\n",
        "            retriever = faiss_retriever # Fallback\n",
        "    else:\n",
        "        print(\"⚠️ BM25 데이터 없어 Dense Retriever(FAISS)만 사용합니다.\")\n",
        "        retriever = faiss_retriever # Fallback\n",
        "else:\n",
        "    print(\"!! Vector Store 준비 안 됨. Retriever 설정 불가.\")\n",
        "\n",
        "print(\"--- 단계 8: Retriever 설정 완료 ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X_3hcxYsxfY"
      },
      "source": [
        "# 9: LLM 설정 (OpenAI - gpt-4.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bBYfQwWsyx9",
        "outputId": "e2e9085e-105e-43f3-f82e-347699ad1758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 9: LLM 설정 시작 (OpenAI) ---\n",
            "[성공] OpenAI (gpt-4.1) LLM 로딩 완료.\n",
            "--- 단계 9: LLM 설정 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 9: LLM 설정 (OpenAI - gpt-4.1) ===\n",
        "\n",
        "print(\"\\n--- 단계 9: LLM 설정 시작 (OpenAI) ---\")\n",
        "llm = None\n",
        "# OpenAI API 키 설정 여부 확인 (단계 2에서 설정됨)\n",
        "if 'OPENAI_API_KEY' in os.environ and os.environ[\"OPENAI_API_KEY\"]:\n",
        "    try:\n",
        "        # === 사용할 OpenAI 모델 지정 ===\n",
        "        # llm_model_name = \"gpt-4o\" # 최신 모델 (성능과 속도 균형)\n",
        "        llm_model_name = \"gpt-4.1\" # 만약 더 작고 빠른 모델이 필요하다면 고려 (현재는 gpt-4o가 가장 유사)\n",
        "        # llm_model_name = \"gpt-3.5-turbo\" # 속도/비용 우선 시 고려\n",
        "        # ==============================\n",
        "\n",
        "        llm = ChatOpenAI(\n",
        "            model=llm_model_name,\n",
        "            temperature=0 # 답변의 창의성 조절 (낮을수록 결정적)\n",
        "            # max_tokens=1024 # 필요시 최대 출력 토큰 수 제한\n",
        "        )\n",
        "        print(f\"[성공] OpenAI ({llm.model_name}) LLM 로딩 완료.\") # .model 대신 .model_name 사용\n",
        "\n",
        "    except ImportError:\n",
        "         print(\"!! [오류] langchain-openai 또는 openai 라이브러리가 설치되지 않았습니다.\")\n",
        "         print(\"   단계 0의 설치 명령을 확인하고 런타임을 재시작하세요.\")\n",
        "    except Exception as e:\n",
        "        print(f\"!! [오류] OpenAI LLM 로딩 실패: {e}\")\n",
        "        traceback.print_exc() # 상세 오류 출력\n",
        "else:\n",
        "    print(\"!! [오류] OpenAI API 키가 설정되지 않았습니다. LLM 로드 불가.\")\n",
        "\n",
        "print(\"--- 단계 9: LLM 설정 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja_TH1uqUQSW"
      },
      "source": [
        "# 10: RAG Chain/파이프라인 구축"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBJ8uY3ms4Zk",
        "outputId": "1548eb3e-fc20-4d5e-adb0-b6c83ac88b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 10: RAG Chain 구축 시작 ---\n",
            "[성공] RetrievalQA Chain 구축 완료.\n",
            "--- 단계 10: RAG Chain 구축 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 10: RAG Chain/파이프라인 구축 ===\n",
        "# (코드 변경 없음 - 단계 9에서 변경된 llm 객체를 사용)\n",
        "print(\"\\n--- 단계 10: RAG Chain 구축 시작 ---\")\n",
        "qa_chain = None\n",
        "if llm and retriever: # llm이 ChatOpenAI 인스턴스로 준비됨\n",
        "    template = \"\"\"당신은 한국의 노무 규정 및 관련 문서에 기반하여 질문에 답변하는 유용한 AI 어시스턴트입니다.\n",
        "\n",
        "[답변 방식]\n",
        "- 질문에 가장 적합한 핵심 정보를 먼저 간결히 제시한 후, 필요한 경우 예시나 조건을 덧붙이십시오.\n",
        "- 일반 사용자가 이해할 수 있도록 법령의 의미를 쉽게 풀어 설명하십시오.\n",
        "- 문서에 없는 수치 표현(예: 5인 이하)이라도 의미가 동일한 경우(예: 4인 미만)로 논리적으로 해석하여 답변하십시오.\n",
        "- 질문에 대한 명확한 정보가 문서에 없더라도, 질문이 일반적이고 상식적이라면 LLM의 일반 지식을 신중하게 보완하여 답변하십시오.\n",
        "- 답변은 두 문단 이내로 작성하며, 너무 많은 예외 조건을 한 번에 나열하지 말고 핵심 하나에 집중하십시오.\n",
        "- 문서에 관련 조항이 명시되어 있는 경우, 판단 보류 없이 해당 조항을 직접 근거로 삼아 명확히 답변하십시오.\n",
        "- 질문에 해당하는 법령에 형사처벌·벌금·과태료 조항이 문서에 명시되어 있으면, 반드시 답변에 포함하십시오.\n",
        "\n",
        "[신뢰성 및 최신 법령 반영 조건]\n",
        "- 답변 시 2025년 기준 최신 개정 법령 내용을 반영하십시오. 예: 육아휴직 최대 1년 6개월 등.\n",
        "- 법 위반 시 제재 수준은 “행정처분”, “과태료”, “형사처벌” 중 구체적으로 구분해 안내하십시오.\n",
        "단, 법령에 명시된 조항(예: 퇴직급여 보장법 제44조) 등이 존재하면 해당 조문을 바탕으로 형사처벌 수위도 구체적으로 안내하십시오.\n",
        "- 법 위반 시의 제재 수준(행정처분, 과태료, 형사처벌 등)은 반드시 문서에 명시된 경우에만 답변하십시오.\n",
        "단, 명확한 조항이 존재하지 않거나 해석이 분분한 경우에는 “문서만으로는 판단이 어렵습니다” 등의 제한 표현을 사용하십시오.\n",
        "- 문서에 근거가 없는 경우에는 처벌 수위에 대해 언급하지 마십시오.\n",
        "- 예외 조항이 존재하는 경우에는 단순히 적용 제외라고 하지 말고, 부분 적용 가능 여부를 구체적으로 명시하십시오.\n",
        "- 법령 해석이 쟁점이거나 분쟁 소지가 있는 경우, 반드시 “문서만으로는 판단이 어렵습니다”라고 안내하십시오.\n",
        "- 단정적이거나 기계적인 표현은 피하고, “현재 정보로는 답변이 어렵습니다.”처럼 부드럽고 책임감 있게 응답하십시오.\n",
        "- 질문이 일반적이고 컨텍스트에 관련 조항이 없을 경우, LLM의 일반적인 법률 지식을 기반으로 보완하되, 문서보다 우선하지 않도록 주의하십시오.\n",
        "- 특히 노동 관련 법령에서 제재 수위는 핵심이므로 누락 없이 서술하십시오.\n",
        "\n",
        "\n",
        "[언어 스타일]\n",
        "- “제공된 문서에 따르면” 등의 기계적 표현은 피하고, 자연스러운 설명형 문장으로 시작하십시오. 예: “이 경우에는 일반적으로…”\n",
        "- “~해야 합니다”보다는 “~할 수 있습니다”, “~로 볼 수 있습니다” 등의 설명형 문장으로 작성하십시오.\n",
        "- “예를 들어” 표현은 매번 반복하지 말고, “예컨대”, “보통 이런 경우”, “예시를 들면” 등 자연스러운 문장 흐름에 맞는 표현으로 다양화하십시오. 필요시 생략하여 매끄러운 흐름을 유지하십시오.\n",
        "- 핵심 쟁점 → 간단한 예시 → 조건/예외 정리 순서로 작성하십시오.\n",
        "- 너무 긴 설명은 피하고, 필요한 경우 “상세한 사항은 근로계약서 또는 회사 내규를 확인할 필요가 있습니다.” 등의 안내로 마무리하십시오.\n",
        "- 마크다운 형식의 굵은 텍스트(**강조**)는 사용하지 마십시오.\n",
        "\n",
        "[정리]\n",
        "- 핵심 정보 → 간결한 예시 → 조건/예외사항 → 책임감 있는 제한 문구 순으로 응답하십시오.\n",
        "- 답변은 간결하고 명확하게, 불필요한 강조나 반복 없이 꼭 필요한 정보만 포함하여 작성하십시오.\"\n",
        "\n",
        "\n",
        "    컨텍스트:\n",
        "    {context}\n",
        "\n",
        "    질문: {question}\n",
        "\n",
        "    답변 (한국어):\"\"\"\n",
        "    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "    try:\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm, # ChatOpenAI 인스턴스 사용\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True,\n",
        "            chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "        )\n",
        "        print(\"[성공] RetrievalQA Chain 구축 완료.\")\n",
        "    except Exception as e: print(f\"!! RAG Chain 구축 실패: {e}\")\n",
        "else: print(\"!! LLM 또는 Retriever 준비 안 됨. RAG Chain 구축 불가.\")\n",
        "print(\"--- 단계 10: RAG Chain 구축 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ut-DOb85HdL"
      },
      "source": [
        "# 11. 질문 리라이터 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXhCNVCia2Nv"
      },
      "outputs": [],
      "source": [
        "# === 질문 리라이터 정의 ===\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "rewrite_prompt = PromptTemplate.from_template(\"\"\"\n",
        "다음 질문을 보다 명확하고 검색에 적합하도록 재구성하십시오. 법률 문서에 근거한 검색이 가능하도록 핵심 개념을 보완하고, 필요한 경우 용어를 구체화하십시오.\n",
        "\n",
        "원래 질문: {question}\n",
        "\n",
        "재작성된 질문:\"\"\")\n",
        "\n",
        "question_rewrite_chain = LLMChain(\n",
        "    llm=llm,  # 단계 9에서 정의한 llm 사용\n",
        "    prompt=rewrite_prompt\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofztdtBAeT3Q"
      },
      "source": [
        "# 12. RAG 시스템 실행 (질의-응답), 질문 리라이터 포함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y28hOGcjeVyV",
        "outputId": "06a642b5-e7a1-45c3-a019-63c3f81cfd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 12: RAG 시스템 실행 시작 ---\n",
            "\n",
            "입력 질문: 시급제로 일하는데, 주말에도 자주 일합니다. 주말 근로는 연장수당으로 쳐야 하나요, 휴일수당으로 쳐야 하나요? 계산 방법이 궁금합니다.\n",
            "🔁 재작성된 질문: 재작성된 질문:  \n",
            "\"시급제 근로자가 주말(토요일 및 일요일)에 근무할 경우, 해당 근로시간이 연장근로수당(근로기준법 제56조) 또는 휴일근로수당(근로기준법 제56조 및 제55조)에 해당하는지, 각각의 수당 산정 기준과 계산 방법은 어떻게 되는지 법률 조항에 근거하여 설명해 주세요.\"\n",
            "답변 생성 중...\n",
            "답변 생성 완료 (5.87초)\n",
            "\n",
            "[최종 답변]:\n",
            "시급제 근로자가 주말(토요일 또는 일요일)에 근무할 경우, 해당 근로가 연장근로수당 또는 휴일근로수당 지급 대상이 되는지는 먼저 그 날이 ‘법정휴일’(주휴일 또는 근로자의 날 등)인지, 그리고 주 40시간(1일 8시간, 1주 5일 기준) 근로시간을 초과했는지에 따라 달라집니다. 근로기준법 제56조에 따르면, 연장근로(법정 근로시간을 초과한 근로)와 휴일근로(법정휴일에 근로한 경우) 모두 통상임금의 50% 이상을 가산하여 지급해야 합니다.\n",
            "\n",
            "예를 들어, 주 5일제 사업장에서 일요일이 주휴일로 지정되어 있고, 근로자가 평일에 이미 40시간을 근무한 뒤 토요일 또는 일요일에 추가로 근무했다면, 토요일 근무는 연장근로수당(통상임금의 1.5배), 일요일 근무는 휴일근로수당(통상임금의 1.5배) 지급 대상이 됩니다. 만약 토요일이 근로일로 지정되어 있고, 주 6일제라면 토요일 근무는 연장근로가 아닌 통상근로가 될 수 있습니다. 휴일근로수당은 법정휴일(주휴일, 근로자의 날 등)에 근로한 경우에만 적용되며, 휴일대체가 적법하게 이루어진 경우에는 휴일근로수당 지급 의무가 없습니다. 상세한 사항은 근로계약서 또는 회사 내규를 확인할 필요가 있습니다.\n",
            "\n",
            "[참고 문서 (Source Documents)]:\n",
            "\n",
            "--- 문서 1 ---\n",
            "제60조제1항ㆍ제2항 및 제6항에 따른 시간외근로 중 1주간에 4시간의 시간\n",
            "외근로에 대하여는 시간외근로수당을 지급하는 것을 갈음하여\n",
            "\n",
            "제70조에 따른 유급휴가 일수에 1개월의 승무기간\n",
            "마다 1일을 추가하여 유급휴가를 주어야 한다.\n",
            " \n",
            "\n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-01T23:49:56+09:00', 'moddate': '2025-04-01T23:49:56+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/선원법(법률)(제20525호)(20250123).pdf', 'total_pages': 40, 'page': 14, 'page_label': '15', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 2 ---\n",
            "제46조제2항에 따라 기준에 못 미치는 휴업수당을 지급하기\n",
            "위하여 승인을 받으려면 별지 제4호서식의 기준 미달의 휴업수당 지급 승인 신청서를 관할 지방노동위원회에 제출\n",
            "하여야 한다.\n",
            "\n",
            "제8조의2(3개월을 초과하는 탄력적 근로시간제에 관한 임금보전방안의 신고) 사용자는 법 \n",
            "\n",
            "제51조의2제5항 본문에 따\n",
            "라 임금보전방안(賃金補塡方案)을 신고하려는 경우에는 별지 제4호의2서식의 임금보전방안 신고서에 임금보전방안\n",
            "의 내용을 확인할 수 있는 서류를 첨부하여 관할 지방고용노동관서의 장에게 제출해야 한다.\n",
            "[본조신설 2021. 4. 5.]\n",
            " \n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-15T10:55:54+09:00', 'moddate': '2025-04-15T10:55:54+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/근로기준법 시행규칙(고용노동부령)(제00436호)(20250223).pdf', 'total_pages': 4, 'page': 1, 'page_label': '2', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 3 ---\n",
            "제50조제1항의 근로시간을 초과한 시간에 대해서는 통상임금의\n",
            "100분의 50 이상을 가산하여 근로자에게 지급할 것. 이 경우\n",
            "\n",
            "제56조제1항은 적용하지 아니한다.\n",
            " \n",
            "\n",
            "\n",
            "제53조(연장 근로의 제한) ① 당사자 간에 합의하면 1주 간에 12시간을 한도로 \n",
            "\n",
            "제50조의 근로시간을 연장할 수 있다.\n",
            "② 당사자 간에 합의하면 1주 간에 12시간을 한도로 \n",
            "\n",
            "제51조 및 \n",
            "\n",
            "제51조의2의 근로시간을 연장할 수 있고, \n",
            "\n",
            "제52조제\n",
            "1항제2호의 정산기간을 평균하여 1주 간에 12시간을 초과하지 아니하는 범위에서 \n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-01T12:35:38+09:00', 'moddate': '2025-04-01T12:35:38+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/근로기준법(법률)(제20520호)(20250223).pdf', 'total_pages': 24, 'page': 11, 'page_label': '12', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 4 ---\n",
            "ground_truths: [\"근로기준법 제56조에 의하면 , 근로자가 휴일근로를 한 경우 사용자는 통상임금의 50%를 가산하여 지급해야하는 바, 구체적인 사실관계는 알 수 없으나 사용자가 휴일에 출장하도록 지시하여 업무를 수행한 것이라면 이는 휴일근로로 봅니다.\",\"한편, ‘휴일대체’는 미리 휴일로 정해진 날을 근로일로 하고 이에 갈음하여 다른 근로일을 휴일로 하는 것으로 취업규칙이나 단체협약 등에 그 근거를 규정하거나 근로자의 동의를 얻어 실시해야 하는데, 근로자가 대체된 휴일이 언제인지 미리 알 수 있도록 구체적으로 지정하여 \n",
            "메타데이터: {'source': 'https://docs.google.com/spreadsheets/d/1QeMvmrcYe6QQ8L1n6o1NQ7ASTPafmzdbuDAAKXFCu3k/edit?gid=0', 'title': 'filtered_qa_dataset - Sheet1', 'row': 46, 'file_type': 'google_sheet'}\n",
            "\n",
            "--- 문서 5 ---\n",
            "제91조의4에 따른 보험급여를 받을 수 있는 사람(이하 “수급권자”라 한다)의 청구에 따\n",
            "라 지급한다.<개정 2010. 5. 20., 2020. 5. 26.>\n",
            "③ 보험급여를 산정하는 경우 해당 근로자의 평균임금을 산정하여야 할 사유가 발생한 날부터 1년이 지난 이후에는\n",
            "매년 전체 근로자의 임금 평균액의 증감률에 따라 평균임금을 증감하되, 그 근로자의 연령이 60세에 도달한 이후에\n",
            "는 소비자물가변동률에 따라 평균임금을 증감한다. 다만, 제6항에 따라 산정한 금액을 평균임금으로 보는 진폐에\n",
            "걸린 근로자에 대한 보험급여는 제외한다.<개정\n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-01T23:41:56+09:00', 'moddate': '2025-04-01T23:41:56+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/산업재해보상보험법(법률)(제20523호)(20250101).pdf', 'total_pages': 34, 'page': 5, 'page_label': '6', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 6 ---\n",
            "제62조제4항에 따른 일시금을 포함한다)\n",
            "5. 상병보상연금\n",
            "6. 장례비\n",
            "7. 직업재활급여\n",
            "8. 진폐보상연금\n",
            "9. 진폐유족연금\n",
            "② 공단은 제1항에 따른 보험급여의 신청 또는 청구를 받으면 보험급여의 지급 여부와 지급 내용 등을 결정하여 청\n",
            "구인에게 알려야 한다.\n",
            "③ 공단은 장해보상연금, 유족보상연금, 진폐보상연금 또는 진폐유족연금을 지급하기로 결정한 경우에는 그 수급권\n",
            "자에게 연금증서를 내주어야 한다.<개정 2010. 11. 15.>\n",
            "\n",
            "제22조(평균임금의 증감) ① 법 \n",
            "\n",
            "제36조제3항 및 제4항에 따른 전체 근로자의 임금 평균액의 \n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-15T11:20:08+09:00', 'moddate': '2025-04-15T11:20:08+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/산업재해보상보험법 시행령(대통령령)(제35160호)(20250101).pdf', 'total_pages': 35, 'page': 4, 'page_label': '5', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 7 ---\n",
            "제6조에 따른 공무원재해보상심의회”는 “급여심의회”로 본다. <개정 2018. 4. 17.,\n",
            "2022. 10. 18.>\n",
            "② 제1항에 따라 준용되는 「공무원연금법」\n",
            "\n",
            "제43조, \n",
            "\n",
            "제51조, \n",
            "\n",
            "제54조, \n",
            "\n",
            "제55조, \n",
            "\n",
            "제58조 및 \n",
            "\n",
            "제62조의 해당 규정에 따른\n",
            "급여의 사유, 재직기간, 재직연수 및 공제재직연수를 산정할 때 \n",
            "\n",
            "제31조제3항 각 호의 구분에 따른 정년을 초과하는\n",
            "기간에 해당하는 재직기간은 계산에서 제외한다.<신설 2016. 5. 29., 2018. 3. 20., 2021. 3. 23.>\n",
            "③ 제2항에 따른 정년의 \n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-02T00:03:02+09:00', 'moddate': '2025-04-02T00:03:02+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/사립학교교직원 연금법(법률)(제20349호)(20240227).pdf', 'total_pages': 18, 'page': 10, 'page_label': '11', 'file_type': 'pdf'}\n",
            "\n",
            "--- 문서 8 ---\n",
            "법제처                                                            6                                                       국가법령정보센터\n",
            "어선원 및 어선 재해보상보험법 시행령\n",
            "권자에게 지급할 해당 보험급여에 따른 각각의 지급일수를 초과하는 일수는 제외한다)에 해당하는 보험급여의 금액\n",
            "을 말한다. 이 경우 그 받은 금품이 요양이면 그 요양에 드는 비용으로 환산한 금액으로 한다.\n",
            "② 제1항을 적용할 때 수급권자에게 지급할 보험급여가 부상 및 질병\n",
            "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2025-04-15T10:50:47+09:00', 'moddate': '2025-04-15T10:50:47+09:00', 'source': '/content/drive/MyDrive/nomu_dataset3/어선원 및 어선 재해보상보험법 시행령(대통령령)(제35044호)(20250101).pdf', 'total_pages': 16, 'page': 5, 'page_label': '6', 'file_type': 'pdf'}\n",
            "\n",
            "--- 단계 12: RAG 시스템 실행 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 12: RAG 시스템 실행 (질의-응답) ===\n",
        "print(\"\\n--- 단계 12: RAG 시스템 실행 시작 ---\")\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# 🔁 질문 리라이터 관련 모듈 및 체인 준비\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "rewrite_prompt = PromptTemplate.from_template(\"\"\"\n",
        "다음 질문을 보다 명확하고 검색에 적합하도록 재구성하십시오. 법률 문서에 근거한 검색이 가능하도록 핵심 개념을 보완하고, 필요한 경우 용어를 구체화하십시오.\n",
        "\n",
        "원래 질문: {question}\n",
        "\n",
        "재작성된 질문:\"\"\")\n",
        "question_rewrite_chain = LLMChain(\n",
        "    llm=llm,  # 단계 9에서 설정한 llm (ChatOpenAI 등)\n",
        "    prompt=rewrite_prompt\n",
        ")\n",
        "\n",
        "# ✅ qa_llm을 사용하여 qa_chain 구성\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=qa_llm,  # 분리된 응답용 LLM 사용\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n",
        "\n",
        "query = \"시급제로 일하는데, 주말에도 자주 일합니다. 주말 근로는 연장수당으로 쳐야 하나요, 휴일수당으로 쳐야 하나요? 계산 방법이 궁금합니다.\"\n",
        "result = None\n",
        "\n",
        "if qa_chain:\n",
        "    print(f\"\\n입력 질문: {query}\")\n",
        "\n",
        "    # ✅ 질문 리라이터 실행\n",
        "    try:\n",
        "        rewritten_query = question_rewrite_chain.run({\"question\": query})\n",
        "        print(f\"🔁 재작성된 질문: {rewritten_query}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 질문 리라이터 실패: {e}\")\n",
        "        rewritten_query = query  # 실패 시 원래 질문 사용\n",
        "\n",
        "    try:\n",
        "        print(\"답변 생성 중...\")\n",
        "        start_qa_time = time.time()\n",
        "\n",
        "        # ✅ 재작성된 질문을 사용하여 RAG 실행\n",
        "        result = qa_chain.invoke({\"query\": rewritten_query})\n",
        "\n",
        "        end_qa_time = time.time()\n",
        "        print(f\"답변 생성 완료 ({end_qa_time - start_qa_time:.2f}초)\")\n",
        "\n",
        "        print(\"\\n[최종 답변]:\")\n",
        "        print(result.get(\"result\", \"N/A\"))\n",
        "\n",
        "        print(\"\\n[참고 문서 (Source Documents)]:\")\n",
        "        source_docs = result.get(\"source_documents\", [])\n",
        "        for i, doc in enumerate(source_docs):\n",
        "            print(f\"\\n--- 문서 {i+1} ---\")\n",
        "            print(doc.page_content[:300])  # 길면 잘라서 출력\n",
        "            print(f\"메타데이터: {doc.metadata}\")\n",
        "    except Exception as e:\n",
        "        print(f\"!! RAG Chain 실행 오류: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"!! RAG Chain 준비 안 됨. 실행 불가.\")\n",
        "\n",
        "print(\"\\n--- 단계 12: RAG 시스템 실행 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjOXXKo7gsW"
      },
      "source": [
        "# 13. RAGAS Retriever 평가(체크포인팅 및 재개 기능 추가)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q2LhEG_W2I7"
      },
      "source": [
        "사용할 Google Sheet 파일 이름\n",
        "\n",
        "GSHEET_FILE_NAME = \"filtered_qa_dataset\"\n",
        "\n",
        "QUESTION_COLUMN = \"question\"\n",
        "\n",
        "ANSWER_COLUMN = \"answer\"             \n",
        "\n",
        "GROUND_TRUTHS_COLUMN = \"ground_truths\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8ML2n_Hjg0"
      },
      "source": [
        "상태 저장: result_dir 아래의 ragas_eval_exec_status.json (마지막 처리 인덱스 저장)\n",
        "\n",
        "결과 저장: result_dir 아래의 ragas_eval_exec_results_partial.csv (배치별 결과 누적 저장)\n",
        "\n",
        "전체 경로 (예시): /content/drive/MyDrive/nomu_rag_result/ragas_eval_exec_status.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2bc674867f7e4c2d84b1e58270f327fd",
            "8285a5dd3574464f979da71f515648df",
            "1a18a1fc87014d69abdecc259b07a04d",
            "0245dcef96164cd59f07325af3938f9d",
            "aec5105c5e9144349651d92c6ce168b1",
            "de2cdb14c4bf4469affab33838a9af43",
            "2bcae4ccb3154040bae44620a101face",
            "8c9d983220de4ee0b9978b418ef77f1f",
            "78d7adb74b804bf5bacfb7ec4f9437c5",
            "ae0f9f9a37c54192aa4c26b1892983e9",
            "835a5bd6c04b4944863ed26677eb1894",
            "b422948351354ec6aba7040f9f913be5",
            "d82a72100519438c94029fe0ea9190df",
            "eb911b0ca23f40df95b17b7471d7bf42",
            "7d434009c3614914941d9c4bd9e7c6cc",
            "cf40aef6fa274688a5c22380b8ccd584",
            "e6a9105102dd4706bb7965f2107963a5",
            "6ef58053abe44fe1a1b6cd2469b566e3",
            "61ea38de2073435fb3e883343aa78b8d",
            "f5916b50441543e28ea8b6c6663d5a2a",
            "200932e22fe84b2ba8ddab4f1c5a948c",
            "3c311dfa9eac4bb4978b32c0e53d33ea",
            "fb98d43d3bc545c6a7482626bedf3a7d",
            "13f89700afa7414cb9148d7c7ec2dd7f",
            "1f503f17ebd24441953d9ed1c89f1b3b",
            "ecd7f025b70a404caf6f4fdf8aa9939d",
            "0cd84dca0e324d18be51b9e3059e9fbd",
            "aaf3bdffca7048928ae0f59a61c52830",
            "e27c691f4daa4dbcb7fd2fa1c098f498",
            "b9a34b5c95c14913ba2dc10787bbf53d",
            "c9f4e5e6193d4fe2a9ab18eb451d0ea0",
            "f57515fec8994b37b641186c06d531e5",
            "2d9daf99233640d3b979ef94b167a20d",
            "2e50c615bc1549129e28a82c8c302f6e",
            "56a85fa237b94d20905c3417963674b3",
            "ad0b9b30df164d4ebe3b8cfe77643852",
            "679fe939f3a84cb4b4a53b83ee6f2b2b",
            "f4e5d34c9bf14005a577746dc85a0ccf",
            "81945432d71d4631973ed30e8f5104a3",
            "9a4af6ac6f444304b38e3e4111327092",
            "5d917cb7a883424e86d43f4a43cb4ead",
            "de8a3d15abe84a9eb1684e9a609a1caa",
            "7f643c68ff3147fe91113c33dd934828",
            "b3ebf64fa14c451499dbee64ca2a0932",
            "a898ef6512344b4bb0b444306fe18be5",
            "aae1e7aead3542cb89a84d38da5b66ff",
            "43bb42a77374460997d8f5d82bcd74fc",
            "36774ad9e6174af19eb5ab6bd0bfa541",
            "eb415dca858948b2846e4242a6bad9c8",
            "485fcc6c6e914614b5e6a7c451859919",
            "985e2a917cfa496d91fd8aad67451f3c",
            "e314f1e8dfa543b29353f1c988e6dc52",
            "bb88999bbbb14c81a951be84612f4480",
            "6972b44b0e91488cb2073d0ebf13bf69",
            "339e9e18b5fa462389bf66a71c1f048a",
            "a966aef35ee7463da0d7780bc9e2fa03",
            "c8d185615c60437ca1bc967de5271771",
            "bf3e89f0831847cdba5b04fd5ca37505",
            "07870d154c1148b5a0afd5caabd2f52c",
            "3a9ef8719c2e4d5192944284d894869b",
            "47d3f71bc47440dcb7e6e89a808c970f",
            "51376e03090c4e1a9e1b7e4561818afe",
            "5682bbf690d34ae781acdbd4e40d5b6b",
            "4502ba9d323146959b83f68052bbfe79",
            "7d06623861cf4bf3beddb8fb10c9ae95",
            "081a4c0ce56948cd92052e5854d8cc9b",
            "53b35e097611448c8539946e071a164e",
            "9f3d97049db74e06a762b9f402a13470",
            "0e7dfe26e2a643938fe9697b8c16a446",
            "1277ed130d114182a0c8406a4235fd99",
            "c9e4333a57f1415ca2679b1e1138c196",
            "1bbeecc0ae224b8f87ced71518780759",
            "bc86a9b284c64467a44dd295b0b7374d",
            "e7e6652091ac47858c42d80799838af0",
            "61d187d275a34d83b34d547f0db183ff",
            "16b6fd35e94c49dfb1b5a313102584f7",
            "40dbb91b02cd4eada25bd22a4d20cc0e",
            "30368e5979324aafb554dec62ff473e2",
            "cce2ad66c277444dafc295bd0a835018",
            "c26207d64e4d4f6fb6ca6cc6b458fc8d",
            "c76058782f3d4e76b9942c4a07d118c8",
            "9a6cf8e6cdff4130a81f673d5faa3c60",
            "7aaf568fcf5d4b6b9be2b9a7c9bcfb22",
            "3c3ce1a4021b4af18d745fa6d9d75f94",
            "4088341daffc4ca6b6e1776c9e7f2b13",
            "f0c1f8519dc1434db2c9c00529de907a",
            "b8776a4eabaf45f98436b8ea432cf10e",
            "540264997d4c444f8e8521f8a8d43281",
            "afc5d9555252467596bcaaa3fcd0a7ec",
            "12ba5eb1e91b4166aee1f2210c6e98e5",
            "035649299d86411e841a47e541eb5d84",
            "55eb518603bc47889072f095ecc28017",
            "c55c982e3f5545a2850c5ef6535bef4a",
            "7beb257e470f40cf98adb7f559c38826",
            "78784f098cdf4c2abe178eff53585bba",
            "af058b28403f45938881bb1400e77b6f",
            "9824c3d8ac80429a9581add30d76adb0",
            "a3f7fb7aa257470db77928c9de4effcd",
            "09700bd377b34086ac86ac40f6ff7ffa",
            "da25622b55c044e6aaeb9c7d9ecc6fe4",
            "cacbfd437ba6431f8f129dcd87f8e348",
            "d494043af91144b2bfc3829b2ad22e35",
            "138893200a9a4d18af9e9e87784b2112",
            "afda7fdc25f846d7adbe2fc04ead5e6f",
            "1757a30adc8f4654a9a33949520a837a",
            "7d2382b2a3634827a6b6d776d91a6d8a",
            "0cb6a06166ab4042b790a29e7478fd31",
            "b0c8d2f6fcac4dee82b6f4c7afd8e559",
            "efb7699fad494b03aadc57db7a5220fe",
            "be8240cf2a2740bf91973bf8b264a25b",
            "c10cdbbc2a4d45cb82773c1a8a6e7152",
            "3087545665aa4576ba91dd851a2c32d3",
            "0259581995774b1293bcf95630461a13",
            "60f81a37697845889f536468c81df201",
            "c3bbd2acf0db47f1aacc2994697bf9d6",
            "aa2f06df96a04e3a97731a26ef13dc69",
            "9316b90db790498b801e5b8f035474b6",
            "f531694bb8ae427497fa9d2cef883bdd",
            "30976cd280924677992b8a60a001ecbe",
            "ff18527f397540f58f1d97f7d8d39f70",
            "e2c68254e9d14bebb01e4389902e3fa8"
          ]
        },
        "id": "K77uoICqbZLh",
        "outputId": "afa7d033-7649-4a85-bbc4-0a24292cabab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 12: RAGAS Retriever 평가 시작 (Google Sheet 데이터 사용) ---\n",
            "[정보] Google Colab 환경 감지됨.\n",
            "[정보] RAGAS 및 관련 라이브러리 임포트 확인\n",
            "\n",
            "--- 13.1: Google 인증 및 gspread 클라이언트 확인 ---\n",
            "[성공] Google 인증 및 gspread 클라이언트 준비 완료.\n",
            "\n",
            "--- 13.2: 필수 객체 확인 및 RAGAS 래퍼 초기화 ---\n",
            "[성공] RAGAS LLM 래퍼 초기화 완료 (모델: gpt-4.1-nano)\n",
            "[정보] RAGAS Embedding 래퍼 초기화 완료 (필요시 사용).\n",
            "[정보] Retriever 객체('retriever') 확인 완료.\n",
            "\n",
            "--- 13.3: 평가 데이터셋 로드 (Google Sheet) ---\n",
            "Google Sheet 'filtered_qa_dataset' 로드 시도...\n",
            "  워크시트 데이터 로딩 중...\n",
            "  [성공] Google Sheet 로드 완료: 89개 행\n",
            "     컬럼 목록: ['No.', 'question', 'answer', 'ground_truths']\n",
            "  [정보] 'ground_truths' 컬럼 확인됨 (context_recall 평가 가능).\n",
            "  [정보] 'answer' 컬럼 확인됨 (context_precision 위한 'reference' 생성 가능).\n",
            "\n",
            "--- 13.4: RAGAS 평가 데이터 준비 ---\n",
            "총 89개 질문에 대해 Contexts 검색 및 RAGAS 형식 변환 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc674867f7e4c2d84b1e58270f327fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "RAGAS 데이터 준비:   0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[완료] RAGAS 평가용 데이터 89개 준비 완료.\n",
            "\n",
            "--- 13.5: Hugging Face Dataset 변환 ---\n",
            "[성공] Hugging Face Dataset으로 변환 완료.\n",
            "   데이터셋 컬럼: ['question', 'contexts', 'reference', 'ground_truths']\n",
            "\n",
            "   데이터셋 샘플 (첫 번째 항목):\n",
            "     question: 근로계약이 미성년자에게 불리하다고 인정되는 경우 미성년후견인은 그 계약을 해지할 수 있나요?\n",
            "     contexts: (List, 6 items) ['No.: 0\\nquestion: 근로계약이 미성년자에게 불리하다고 인정되는 경우 미성년후견인은 그 계약을 해지할 수 있나요?\\nanswer: 네. 근로계약을 해지할 수 있습니다...\n",
            "     reference: 네. 근로계약을 해지할 수 있습니다.\n",
            "     ground_truths: (List, 1 items) [['[\"「근로기준법」 제67조 제2항은 친권자,후견인 또는 고용노동부장관은 근로계약이 미성년자에게 불리하다고 인정하는 경우에는 이를 해지할 수 있다.\"라고 규정하고 있습니다.\"]...\n",
            "\n",
            "--- 13.6: RAGAS 평가 실행 (배치 처리 및 시간 지연 추가) ---\n",
            "평가 지표: ['context_precision', 'context_recall']\n",
            "총 89개 항목을 10개씩 배치 처리...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b422948351354ec6aba7040f9f913be5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "전체 평가 진행률:   0%|          | 0/89 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 배치 처리 시작: 인덱스 0 ~ 9 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb98d43d3bc545c6a7482626bedf3a7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 20.59초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 10 ~ 19 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e50c615bc1549129e28a82c8c302f6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 12.28초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 20 ~ 29 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a898ef6512344b4bb0b444306fe18be5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 23.42초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 30 ~ 39 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a966aef35ee7463da0d7780bc9e2fa03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 10.09초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 40 ~ 49 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53b35e097611448c8539946e071a164e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 11.04초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 50 ~ 59 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30368e5979324aafb554dec62ff473e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 26.93초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 60 ~ 69 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc5d9555252467596bcaaa3fcd0a7ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 13.06초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 70 ~ 79 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 10)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da25622b55c044e6aaeb9c7d9ecc6fe4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 12.55초\n",
            "  배치 평가 완료. 결과 10개 행 생성.\n",
            "\n",
            "  정상 처리 완료. 다음 배치를 위해 5초 대기...\n",
            "\n",
            "--- 배치 처리 시작: 인덱스 80 ~ 88 ---\n",
            "  RAGAS evaluate() 호출 (배치 크기: 9)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c10cdbbc2a4d45cb82773c1a8a6e7152",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  RAGAS evaluate() 실행 시간: 12.10초\n",
            "  배치 평가 완료. 결과 9개 행 생성.\n",
            "\n",
            "[성공] 전체 89개 항목에 대한 RAGAS 평가 결과 통합 완료.\n",
            "  최종 결과가 'ragas_eval_retriever_results_final.csv'에 저장되었습니다.\n",
            "\n",
            "--- 13.7: RAGAS Retriever 전체 평가 결과 요약 ---\n",
            "\n",
            "=== 전체 결과 (요약) ===\n",
            "    context_precision  context_recall\n",
            "0              0.9167          1.0000\n",
            "1              1.0000          1.0000\n",
            "2              1.0000          1.0000\n",
            "3              1.0000          1.0000\n",
            "4              1.0000          1.0000\n",
            "5              0.9667          1.0000\n",
            "6              0.7000          1.0000\n",
            "7              1.0000          1.0000\n",
            "8              1.0000          1.0000\n",
            "9              0.8333          1.0000\n",
            "10             0.7500          1.0000\n",
            "11             0.8056          1.0000\n",
            "12             0.9167          1.0000\n",
            "13             1.0000          1.0000\n",
            "14             1.0000          1.0000\n",
            "15             1.0000          1.0000\n",
            "16             0.7500          1.0000\n",
            "17             0.8929          1.0000\n",
            "18             1.0000          1.0000\n",
            "19             1.0000          1.0000\n",
            "20             0.8042          1.0000\n",
            "21             1.0000          1.0000\n",
            "22             0.9500          1.0000\n",
            "23             1.0000          1.0000\n",
            "24             0.5000          1.0000\n",
            "25             0.8875          1.0000\n",
            "26             1.0000          1.0000\n",
            "27             0.9167          1.0000\n",
            "28             0.9667          1.0000\n",
            "29             1.0000          0.8571\n",
            "30             1.0000          1.0000\n",
            "31             1.0000          0.5000\n",
            "32             1.0000          0.0000\n",
            "33             1.0000          1.0000\n",
            "34             1.0000          1.0000\n",
            "35             1.0000          1.0000\n",
            "36             1.0000          1.0000\n",
            "37             1.0000          1.0000\n",
            "38             1.0000          1.0000\n",
            "39             1.0000          1.0000\n",
            "40             1.0000          1.0000\n",
            "41             1.0000          1.0000\n",
            "42             0.9667          1.0000\n",
            "43             1.0000          1.0000\n",
            "44             0.6667          1.0000\n",
            "45             1.0000          1.0000\n",
            "46             1.0000          0.6667\n",
            "47             1.0000          1.0000\n",
            "48             1.0000          0.0000\n",
            "49             0.8875          1.0000\n",
            "50             0.9167          1.0000\n",
            "51             1.0000          1.0000\n",
            "52             1.0000          1.0000\n",
            "53             0.8167          1.0000\n",
            "54             1.0000          1.0000\n",
            "55             0.9429          1.0000\n",
            "56             1.0000          1.0000\n",
            "57             0.7500          0.9375\n",
            "58             0.8056          1.0000\n",
            "59             0.6429          1.0000\n",
            "60             1.0000          1.0000\n",
            "61             1.0000          1.0000\n",
            "62             0.7556          1.0000\n",
            "63             1.0000          1.0000\n",
            "64             0.8333          1.0000\n",
            "65             0.9167          0.2857\n",
            "66             1.0000          1.0000\n",
            "67             0.9167          1.0000\n",
            "68             0.7500          1.0000\n",
            "69             0.9667          1.0000\n",
            "70             0.7500          1.0000\n",
            "71             0.8333          1.0000\n",
            "72             1.0000          1.0000\n",
            "73             1.0000          1.0000\n",
            "74             0.9762          1.0000\n",
            "75             0.8333          1.0000\n",
            "76             0.8762          1.0000\n",
            "77             0.8095          1.0000\n",
            "78             0.9500          1.0000\n",
            "79             0.9167          1.0000\n",
            "80             1.0000          1.0000\n",
            "81             1.0000          0.6667\n",
            "82             0.8542          1.0000\n",
            "83             0.8667          1.0000\n",
            "84             1.0000          1.0000\n",
            "85             0.7000          1.0000\n",
            "86             0.8875          1.0000\n",
            "87             1.0000          1.0000\n",
            "88             1.0000          1.0000\n",
            "\n",
            "=== 지표별 통계 (NaN 제외) ===\n",
            "       context_precision  context_recall\n",
            "count            89.0000         89.0000\n",
            "mean              0.9252          0.9541\n",
            "std               0.1068          0.1790\n",
            "min               0.5000          0.0000\n",
            "25%               0.8762          1.0000\n",
            "50%               1.0000          1.0000\n",
            "75%               1.0000          1.0000\n",
            "max               1.0000          1.0000\n",
            "\n",
            "[정보] 모든 유효 항목에 대해 점수가 성공적으로 계산되었습니다.\n",
            "\n",
            "**참고:**\n",
            "  - 'context_recall'은(는) Google Sheet 'ground_truths' 컬럼을 참조했습니다.\n",
            "  - 'context_precision'은(는) Google Sheet 'answer' 컬럼 (-> 'reference')을 참조했습니다.\n",
            "\n",
            "--- 단계 13: Retriever 성능 평가 (RAGAS, Google Sheet) 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 13: RAGAS Retriever 평가 (filtered_qa_dataset 사용) ===\n",
        "\n",
        "# 기능:\n",
        "# 1. Google Sheet ('filtered_qa_dataset')에서 평가 데이터셋 로드.\n",
        "# 2. 각 'question'에 대해 Retriever를 실행하여 'contexts' 검색.\n",
        "# 3. RAGAS 데이터 형식에 맞게 변환 ('question', 'contexts', 'reference', 'ground_truths').\n",
        "# 4. RAGAS evaluate()를 사용하여 'context_precision' 및 'context_recall' 계산.\n",
        "# 5. 결과 요약 및 출력 (배치 처리 및 시간 지연 포함).\n",
        "\n",
        "# --- 13.0: 필요 라이브러리 임포트 및 재확인 ---\n",
        "print(\"\\n--- 단계 12: RAGAS Retriever 평가 시작 (Google Sheet 데이터 사용) ---\")\n",
        "import os\n",
        "import pandas as pd\n",
        "import gspread\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import json\n",
        "import warnings\n",
        "import traceback # 상세 오류 출력\n",
        "\n",
        "# Google Colab/Auth 관련\n",
        "try:\n",
        "    from google.colab import auth\n",
        "    print(\"[정보] Google Colab 환경 감지됨.\")\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    print(\"[정보] Google Colab 환경 아님. 로컬 인증 가정.\")\n",
        "    COLAB_ENV = False\n",
        "from google.auth import default as google_auth_default\n",
        "\n",
        "# RAGAS 및 관련 라이브러리 임포트 (오류 발생 시 메시지 출력)\n",
        "try:\n",
        "    from datasets import Dataset\n",
        "    from ragas import evaluate\n",
        "    # Retriever 평가 메트릭\n",
        "    from ragas.metrics import context_precision, context_recall\n",
        "    # RAGAS 래퍼 클래스 (최신 버전 호환)\n",
        "    from ragas.llms import LangchainLLMWrapper\n",
        "    from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "    print(\"[정보] RAGAS 및 관련 라이브러리 임포트 확인\")\n",
        "    RAGAS_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(f\"!! [오류] RAGAS 관련 라이브러리 임포트 실패: {e}\")\n",
        "    print(\"   `ragas==0.2.15` 및 `datasets` 설치를 확인하세요.\")\n",
        "    Dataset = None; evaluate = None; context_precision = None; context_recall = None;\n",
        "    LangchainLLMWrapper = None; LangchainEmbeddingsWrapper = None\n",
        "    RAGAS_AVAILABLE = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") # 경고 메시지 숨기기 (선택 사항)\n",
        "\n",
        "# --- 13.1: Google 인증 및 gspread 클라이언트 확인 ---\n",
        "print(\"\\n--- 13.1: Google 인증 및 gspread 클라이언트 확인 ---\")\n",
        "gc = None # gspread 클라이언트 초기화\n",
        "try:\n",
        "    # Colab에서는 이전 단계 인증 사용, 로컬에서는 gcloud auth login 등 필요\n",
        "    creds, _ = google_auth_default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    print(\"[성공] Google 인증 및 gspread 클라이언트 준비 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"!! [실패] Google 인증 또는 gspread 클라이언트 생성 오류: {e}.\")\n",
        "    print(\"   Colab 환경이 아니거나 인증 정보가 유효하지 않을 수 있습니다.\")\n",
        "\n",
        "# --- 13.2: 필수 객체 확인 및 RAGAS 래퍼 초기화 ---\n",
        "print(\"\\n--- 13.2: 필수 객체 확인 및 RAGAS 래퍼 초기화 ---\")\n",
        "\n",
        "# 평가용 LLM, Retriever, Embeddings 객체 확인 (이전 단계에서 정의됨)\n",
        "# RAGAS 평가는 eval_llm 사용 권장\n",
        "llm_available = 'eval_llm' in locals() and eval_llm is not None\n",
        "retriever_available = 'retriever' in locals() and retriever is not None\n",
        "# Embeddings는 context_precision/recall에 직접 필요 없으나, 다른 메트릭 위해 확인\n",
        "embeddings_available = 'embeddings' in locals() and embeddings is not None\n",
        "\n",
        "ragas_llm = None\n",
        "ragas_embeddings = None\n",
        "\n",
        "if RAGAS_AVAILABLE:\n",
        "    # LLM 래퍼 초기화 (평가용 eval_llm 사용)\n",
        "    if llm_available:\n",
        "        if LangchainLLMWrapper:\n",
        "            try:\n",
        "                ragas_llm = LangchainLLMWrapper(eval_llm) # 키워드 인자 없이 객체만 전달\n",
        "                print(f\"[성공] RAGAS LLM 래퍼 초기화 완료 (모델: {eval_llm.model_name})\") # eval_llm 사용\n",
        "            except Exception as e:\n",
        "                print(f\"!! [오류] RAGAS LLM 래퍼 초기화 실패: {e}\"); llm_available = False\n",
        "        else:\n",
        "             print(\"!! Ragas LLM 래퍼 클래스 임포트 실패.\")\n",
        "             llm_available = False\n",
        "    else:\n",
        "        print(\"!! [오류] 평가용 LLM 객체('eval_llm')가 정의되지 않았습니다.\")\n",
        "\n",
        "    # Embedding 래퍼 초기화 (선택 사항)\n",
        "    if embeddings_available:\n",
        "        if LangchainEmbeddingsWrapper:\n",
        "            try:\n",
        "                ragas_embeddings = LangchainEmbeddingsWrapper(embeddings) # 키워드 인자 없이 객체만 전달\n",
        "                print(\"[정보] RAGAS Embedding 래퍼 초기화 완료 (필요시 사용).\")\n",
        "            except Exception as e:\n",
        "                print(f\"!! [경고] RAGAS Embedding 래퍼 초기화 오류: {e}.\"); embeddings_available = False\n",
        "        else:\n",
        "             print(\"!! Ragas Embedding 래퍼 클래스 임포트 실패.\")\n",
        "    else:\n",
        "        print(\"[정보] Embedding 객체('embeddings') 없음.\")\n",
        "else:\n",
        "    print(\"!! RAGAS 라이브러리 임포트 실패. RAGAS 평가 불가.\")\n",
        "\n",
        "# Retriever 존재 확인\n",
        "if retriever_available: print(\"[정보] Retriever 객체('retriever') 확인 완료.\")\n",
        "else: print(\"!! [오류] Retriever 객체('retriever') 없음. 평가 불가.\")\n",
        "\n",
        "# --- 13.3: 평가 데이터셋 로드 (Google Sheet: filtered_qa_dataset) ---\n",
        "print(\"\\n--- 13.3: 평가 데이터셋 로드 (Google Sheet) ---\")\n",
        "# 사용할 Google Sheet 파일 이름 및 컬럼명\n",
        "GSHEET_FILE_NAME = \"filtered_qa_dataset\"\n",
        "QUESTION_COLUMN = \"question\"        # 질문 컬럼\n",
        "ANSWER_COLUMN = \"answer\"            # Ground Truth 답변 컬럼 (-> RAGAS 'reference')\n",
        "GROUND_TRUTHS_COLUMN = \"ground_truths\" # Ground Truth 문서/구절 컬럼 (-> RAGAS 'ground_truths')\n",
        "\n",
        "qa_df = pd.DataFrame() # 데이터 로드용 DataFrame 초기화\n",
        "ground_truths_column_exists = False # context_recall 평가 가능 여부 플래그\n",
        "answer_column_exists = False        # context_precision 평가 가능 여부 플래그 (reference 컬럼 생성용)\n",
        "\n",
        "if gc: # Google Sheet 클라이언트 준비 시\n",
        "    print(f\"Google Sheet '{GSHEET_FILE_NAME}' 로드 시도...\")\n",
        "    try:\n",
        "        spreadsheet = gc.open(GSHEET_FILE_NAME)\n",
        "        worksheet = spreadsheet.get_worksheet(0) # 첫 번째 시트 사용\n",
        "        print(\"  워크시트 데이터 로딩 중...\")\n",
        "        data = worksheet.get_all_values()\n",
        "        if len(data) > 1: # 헤더 포함 최소 2줄\n",
        "            qa_df = pd.DataFrame(data[1:], columns=data[0]) # 첫 행은 헤더\n",
        "            print(f\"  [성공] Google Sheet 로드 완료: {len(qa_df)}개 행\")\n",
        "            print(f\"     컬럼 목록: {qa_df.columns.tolist()}\")\n",
        "\n",
        "            # 필수/선택 컬럼 확인\n",
        "            if QUESTION_COLUMN not in qa_df.columns:\n",
        "                raise ValueError(f\"필수 컬럼 '{QUESTION_COLUMN}'이 시트에 없습니다.\")\n",
        "            if GROUND_TRUTHS_COLUMN in qa_df.columns:\n",
        "                ground_truths_column_exists = True\n",
        "                print(f\"  [정보] '{GROUND_TRUTHS_COLUMN}' 컬럼 확인됨 (context_recall 평가 가능).\")\n",
        "            else:\n",
        "                print(f\"  !! [경고] '{GROUND_TRUTHS_COLUMN}' 컬럼 없음. context_recall 점수는 0이 됩니다.\")\n",
        "            if ANSWER_COLUMN in qa_df.columns:\n",
        "                answer_column_exists = True\n",
        "                print(f\"  [정보] '{ANSWER_COLUMN}' 컬럼 확인됨 (context_precision 위한 'reference' 생성 가능).\")\n",
        "            else:\n",
        "                # Context Precision은 reference(정답)가 필요하므로 경고\n",
        "                print(f\"  !! [경고] '{ANSWER_COLUMN}' 컬럼 없음. context_precision 평가 불가.\")\n",
        "        else:\n",
        "            print(\"  !! [오류] Google Sheet에 헤더 외 데이터가 없습니다.\")\n",
        "            qa_df = pd.DataFrame()\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        print(f\"  !! [오류] Google Sheet '{GSHEET_FILE_NAME}'을(를) 찾을 수 없습니다.\")\n",
        "        qa_df = pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"  !! [오류] Google Sheet 로드 중 예상치 못한 오류: {e}\")\n",
        "        traceback.print_exc()\n",
        "        qa_df = pd.DataFrame()\n",
        "else:\n",
        "    print(\"!! Google Sheet 클라이언트(gc)가 준비되지 않아 데이터셋을 로드할 수 없습니다.\")\n",
        "\n",
        "# --- 13.4: RAGAS 평가 데이터 준비 (Retriever 실행 포함) ---\n",
        "print(\"\\n--- 13.4: RAGAS 평가 데이터 준비 ---\")\n",
        "eval_data_list = []\n",
        "# DataFrame이 비어있고, Retriever 준비되었을 때만 진행\n",
        "if not qa_df.empty and retriever_available:\n",
        "    print(f\"총 {len(qa_df)}개 질문에 대해 Contexts 검색 및 RAGAS 형식 변환 중...\")\n",
        "    for index, row in tqdm(qa_df.iterrows(), total=qa_df.shape[0], desc=\"RAGAS 데이터 준비\"):\n",
        "        question_text = row.get(QUESTION_COLUMN)\n",
        "        if pd.isna(question_text) or not str(question_text).strip():\n",
        "            continue # 질문 없으면 건너<0xEB><0x9B><0x81>기\n",
        "        question_text = str(question_text).strip()\n",
        "\n",
        "        # Ground Truth Answer (for context_precision -> 'reference')\n",
        "        reference_text = str(row.get(ANSWER_COLUMN, \"\")).strip() if answer_column_exists else \"\"\n",
        "\n",
        "        # Ground Truth Documents/Passages (for context_recall -> 'ground_truths')\n",
        "        ground_truths_input = row.get(GROUND_TRUTHS_COLUMN, \"[]\") if ground_truths_column_exists else \"[]\"\n",
        "        ground_truths_list = [] # RAGAS 'ground_truths'용 리스트\n",
        "\n",
        "        retrieved_contexts = [] # RAGAS 'contexts'용 리스트\n",
        "\n",
        "        try:\n",
        "            # 1. Ground Truths (문서/구절) 파싱\n",
        "            if ground_truths_column_exists and isinstance(ground_truths_input, str) and ground_truths_input.strip():\n",
        "                try:\n",
        "                    parsed_list = json.loads(ground_truths_input) # JSON 배열 \"[...]\" 형식 가정\n",
        "                    if isinstance(parsed_list, list):\n",
        "                        ground_truths_list = [str(item).strip() for item in parsed_list if item is not None and str(item).strip()]\n",
        "                    else: # JSON 파싱은 됐으나 리스트 아님\n",
        "                         ground_truths_list = [ground_truths_input.strip()] # 원본 문자열 사용\n",
        "                except (json.JSONDecodeError, TypeError): # JSON 파싱 실패 시\n",
        "                    ground_truths_list = [ground_truths_input.strip()] # 원본 문자열 사용\n",
        "            elif isinstance(ground_truths_input, list): # 이미 리스트 형태인 경우\n",
        "                 ground_truths_list = [str(item).strip() for item in ground_truths_input if item is not None and str(item).strip()]\n",
        "\n",
        "            # 2. Retriever 실행하여 Contexts 검색\n",
        "            retrieved_docs = retriever.invoke(question_text)\n",
        "            retrieved_contexts = [doc.page_content for doc in retrieved_docs]\n",
        "\n",
        "            # 3. RAGAS 평가 데이터 형식으로 구성\n",
        "            eval_item = {\n",
        "                \"question\": question_text,         # 질문\n",
        "                \"contexts\": retrieved_contexts,    # 검색된 문서 내용 리스트\n",
        "                \"reference\": reference_text,       # Ground Truth 답변 (ANSWER_COLUMN 값)\n",
        "                \"ground_truths\": [ground_truths_list] # Ground Truth 문서/구절 리스트 (주의: 리스트의 리스트 형태)\n",
        "                # Ragas 0.1.x에서 context_recall은 ground_truths 컬럼이 List[List[str]] 형태를 기대함\n",
        "            }\n",
        "            eval_data_list.append(eval_item)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n!! 데이터 준비 중 오류 (질문 #{index}: '{question_text[:50]}...'): {e}\")\n",
        "            traceback.print_exc()\n",
        "            # 오류 발생 시 빈 데이터 추가는 피하거나, 필요한 최소 정보만 넣어 에러 방지\n",
        "            # eval_data_list.append({\"question\": question_text, \"contexts\": [], \"reference\": \"\", \"ground_truths\": [[]]})\n",
        "\n",
        "    print(f\"[완료] RAGAS 평가용 데이터 {len(eval_data_list)}개 준비 완료.\")\n",
        "else:\n",
        "    if qa_df.empty: print(\"!! 평가 데이터(qa_df)가 비어있거나 로드되지 않아 데이터 준비 불가.\")\n",
        "    if not retriever_available: print(\"!! Retriever가 없어 Contexts를 검색할 수 없으므로 데이터 준비 불가.\")\n",
        "\n",
        "# --- 13.5: Hugging Face Dataset 형식으로 변환 ---\n",
        "print(\"\\n--- 13.5: Hugging Face Dataset 변환 ---\")\n",
        "eval_dataset = None\n",
        "if eval_data_list and Dataset: # Dataset 클래스 로드 성공 시\n",
        "    try:\n",
        "        eval_dataset = Dataset.from_list(eval_data_list)\n",
        "        print(\"[성공] Hugging Face Dataset으로 변환 완료.\")\n",
        "        print(f\"   데이터셋 컬럼: {eval_dataset.column_names}\")\n",
        "        # 생성된 컬럼 확인 (context_precision, context_recall에 필요한 컬럼 포함 여부)\n",
        "        required_eval_cols = {'question', 'contexts', 'reference', 'ground_truths'}\n",
        "        if not required_eval_cols.issubset(eval_dataset.column_names):\n",
        "             print(f\"   !! [경고] 데이터셋에 RAGAS 평가 필수 컬럼 일부 누락! 필요: {required_eval_cols}\")\n",
        "        # 샘플 데이터 확인 (처음 1개)\n",
        "        if len(eval_dataset) > 0:\n",
        "            print(\"\\n   데이터셋 샘플 (첫 번째 항목):\")\n",
        "            sample_item = eval_dataset[0]\n",
        "            for key, value in sample_item.items():\n",
        "                 print(f\"     {key}: \", end=\"\")\n",
        "                 preview_limit = 100 # 미리보기 글자 수\n",
        "                 if isinstance(value, list):\n",
        "                     preview = str(value)[:preview_limit] + ('...' if len(str(value)) > preview_limit else '')\n",
        "                     print(f\"(List, {len(value)} items) {preview}\")\n",
        "                 else:\n",
        "                     preview = str(value)[:preview_limit] + ('...' if len(str(value)) > preview_limit else '')\n",
        "                     print(f\"{preview}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!! [오류] Dataset 변환 중 오류: {e}\"); traceback.print_exc(); eval_dataset = None\n",
        "else:\n",
        "    print(\"!! [정보] 생성된 평가 데이터가 없거나 Dataset 클래스 로드 실패하여 변환 불가.\")\n",
        "\n",
        "# --- 13.6: RAGAS 평가 실행 (배치 처리 및 시간 지연 추가) ---\n",
        "print(\"\\n--- 13.6: RAGAS 평가 실행 (배치 처리 및 시간 지연 추가) ---\")\n",
        "evaluation_results_df = None # 평가 결과 저장 DataFrame 초기화\n",
        "all_results_list = [] # 배치 결과 누적용 리스트\n",
        "eval_batch_size = 10   # ===> 배치 크기 설정 (API 제한, 리소스 고려하여 조절) <===\n",
        "seconds_to_wait_between_batches = 5 # ===> 배치 간 대기 시간 (초) <===\n",
        "# seconds_to_wait_on_error = 30    # ===> 오류 발생 시 다음 배치 전 대기 시간 (초) <===\n",
        "\n",
        "# 평가 실행 조건 확인\n",
        "evaluation_possible = (\n",
        "    RAGAS_AVAILABLE and\n",
        "    llm_available and ragas_llm is not None and # LLM 및 RAGAS 래퍼 준비\n",
        "    retriever_available and                     # Retriever 준비 (Context 생성용)\n",
        "    eval_dataset and                            # Dataset 준비\n",
        "    evaluate and context_precision and context_recall # Ragas 함수/메트릭 확인\n",
        ")\n",
        "\n",
        "if evaluation_possible:\n",
        "    # 사용할 평가 지표 정의 (데이터 준비 상태에 따라 결정)\n",
        "    metrics_to_evaluate = []\n",
        "    if context_precision and answer_column_exists: # 'reference' 생성 가능 시\n",
        "        metrics_to_evaluate.append(context_precision)\n",
        "    if context_recall and ground_truths_column_exists: # 'ground_truths' 준비 가능 시\n",
        "        metrics_to_evaluate.append(context_recall)\n",
        "\n",
        "    if not metrics_to_evaluate:\n",
        "        print(\"!! [오류] 평가할 유효한 RAGAS 메트릭이 없습니다 (데이터 컬럼 부족 가능성).\")\n",
        "        print(f\"   (Answer 컬럼 존재: {answer_column_exists}, GroundTruths 컬럼 존재: {ground_truths_column_exists})\")\n",
        "    else:\n",
        "        print(f\"평가 지표: {[m.name for m in metrics_to_evaluate]}\")\n",
        "        print(f\"총 {len(eval_dataset)}개 항목을 {eval_batch_size}개씩 배치 처리...\")\n",
        "\n",
        "        overall_progress = tqdm(total=len(eval_dataset), desc=\"전체 평가 진행률\")\n",
        "\n",
        "        # 배치 처리 루프\n",
        "        for i in range(0, len(eval_dataset), eval_batch_size):\n",
        "            batch_start_index = i\n",
        "            batch_end_index = min(i + eval_batch_size, len(eval_dataset))\n",
        "            print(f\"\\n--- 배치 처리 시작: 인덱스 {batch_start_index} ~ {batch_end_index - 1} ---\")\n",
        "            # 현재 배치 데이터셋 선택\n",
        "            batch_dataset = eval_dataset.select(range(batch_start_index, batch_end_index))\n",
        "\n",
        "            if len(batch_dataset) == 0:\n",
        "                 print(\"  [정보] 현재 배치가 비어있어 건너<0xEB><0x9B><0x81>니다.\")\n",
        "                 continue\n",
        "\n",
        "            try:\n",
        "                # RAGAS 평가 실행\n",
        "                print(f\"  RAGAS evaluate() 호출 (배치 크기: {len(batch_dataset)})...\")\n",
        "                eval_start_time = time.time()\n",
        "                # 최신 Ragas(0.1.x+) 는 evaluate()에 batch_size 인자가 없을 수 있음.\n",
        "                # 대신 Dataset 크기 또는 내부 구현에 따라 처리됨.\n",
        "                batch_result = evaluate(\n",
        "                    dataset=batch_dataset,           # 현재 배치 데이터셋\n",
        "                    metrics=metrics_to_evaluate,    # 평가 지표 리스트\n",
        "                    llm=ragas_llm,                  # Ragas LLM 래퍼\n",
        "                    embeddings=ragas_embeddings if embeddings_available else None # 필요시 전달\n",
        "                    # raise_exceptions=False # 오류 발생 시 NaN 반환 (기본값)\n",
        "                )\n",
        "                eval_end_time = time.time()\n",
        "                print(f\"  RAGAS evaluate() 실행 시간: {eval_end_time - eval_start_time:.2f}초\")\n",
        "\n",
        "                # 결과 처리 및 누적\n",
        "                if batch_result:\n",
        "                    # Ragas 결과는 Dataset 객체일 수 있음 -> DataFrame 변환\n",
        "                    try:\n",
        "                        batch_result_df = batch_result.to_pandas()\n",
        "                        print(f\"  배치 평가 완료. 결과 {len(batch_result_df)}개 행 생성.\")\n",
        "                        all_results_list.extend(batch_result_df.to_dict('records')) # 결과 누적\n",
        "                    except AttributeError:\n",
        "                        print(\"!! 배치 결과가 Pandas DataFrame으로 변환 불가. Raw 결과 저장 시도.\")\n",
        "                        # 결과가 딕셔너리 등 다른 형태일 경우 처리 (덜 일반적)\n",
        "                        if isinstance(batch_result, dict):\n",
        "                            # 딕셔너리 결과를 리스트에 맞게 변환 필요\n",
        "                             print(\"결과가 딕셔너리 형태입니다. 처리 방식 확인 필요.\")\n",
        "                             # 예시: all_results_list.append(batch_result) 또는 변환 로직\n",
        "                        else: print(f\"처리할 수 없는 결과 타입: {type(batch_result)}\")\n",
        "                    except Exception as e_conv: print(f\"!! 결과 변환/저장 중 오류: {e_conv}\")\n",
        "\n",
        "                    overall_progress.update(len(batch_dataset)) # 성공 시 진행률 업데이트\n",
        "                else:\n",
        "                    print(\"!! 배치 평가 결과가 비어있습니다 (None 또는 빈 객체).\")\n",
        "                    overall_progress.update(len(batch_dataset)) # 결과 없어도 처리한 것으로 간주\n",
        "\n",
        "                # API Rate Limit 방지 위한 대기 (마지막 배치 제외)\n",
        "                if batch_end_index < len(eval_dataset):\n",
        "                    print(f\"\\n  정상 처리 완료. 다음 배치를 위해 {seconds_to_wait_between_batches}초 대기...\")\n",
        "                    time.sleep(seconds_to_wait_between_batches)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"!! [오류] 배치 {batch_start_index}~{batch_end_index-1} RAGAS 평가 중 심각한 오류 발생: {e}\")\n",
        "                print(\"   다음 배치로 넘어갑니다. API 할당량, 네트워크, 입력 데이터 형식 등을 확인하세요.\")\n",
        "                traceback.print_exc()\n",
        "                overall_progress.update(len(batch_dataset)) # 오류 발생 시에도 해당 배치 처리한 것으로 간주\n",
        "                # 오류 시 대기 (마지막 배치 제외)\n",
        "                if batch_end_index < len(eval_dataset):\n",
        "                     print(f\"  오류 발생. 다음 배치를 위해 {seconds_to_wait_on_error}초 대기...\")\n",
        "                     time.sleep(seconds_to_wait_on_error)\n",
        "\n",
        "        overall_progress.close() # 전체 진행률 표시 완료\n",
        "\n",
        "        # 최종 결과 통합\n",
        "        if all_results_list:\n",
        "            try:\n",
        "                evaluation_results_df = pd.DataFrame(all_results_list)\n",
        "                print(f\"\\n[성공] 전체 {len(evaluation_results_df)}개 항목에 대한 RAGAS 평가 결과 통합 완료.\")\n",
        "                # (선택) 최종 결과 파일 저장\n",
        "                if 'result_dir' in locals() and result_dir and os.path.isdir(result_dir):\n",
        "                    final_results_file = os.path.join(result_dir, \"ragas_eval_retriever_results_final.csv\")\n",
        "                    evaluation_results_df.to_csv(final_results_file, index=False, encoding='utf-8-sig')\n",
        "                    print(f\"  최종 결과가 '{os.path.basename(final_results_file)}'에 저장되었습니다.\")\n",
        "            except Exception as df_e:\n",
        "                 print(f\"!! 최종 DataFrame 생성 또는 저장 중 오류: {df_e}\")\n",
        "        else:\n",
        "            print(\"\\n[정보] 처리된 결과가 없어 최종 DataFrame을 생성할 수 없습니다.\")\n",
        "\n",
        "else:\n",
        "    # 평가 실행 불가 사유 요약\n",
        "    missing_components = []\n",
        "    if not RAGAS_AVAILABLE: missing_components.append(\"RAGAS 라이브러리\")\n",
        "    if not llm_available: missing_components.append(\"LLM/RAGAS 래퍼\")\n",
        "    if not retriever_available: missing_components.append(\"Retriever\")\n",
        "    if not eval_dataset: missing_components.append(\"평가 데이터셋\")\n",
        "    if not (evaluate and context_precision and context_recall): missing_components.append(\"RAGAS 함수/메트릭\")\n",
        "    print(f\"!! {', '.join(missing_components)} 준비 안 됨. RAGAS 평가 불가.\")\n",
        "\n",
        "# --- 13.7: 전체 평가 결과 요약 ---\n",
        "print(\"\\n--- 13.7: RAGAS Retriever 전체 평가 결과 요약 ---\")\n",
        "if evaluation_results_df is not None and not evaluation_results_df.empty:\n",
        "    # 실제로 평가된 메트릭 컬럼만 사용\n",
        "    evaluated_metrics = [m.name for m in metrics_to_evaluate if m and m.name in evaluation_results_df.columns]\n",
        "    if evaluated_metrics:\n",
        "        print(\"\\n=== 전체 결과 (요약) ===\")\n",
        "        # NaN 값을 'NaN' 문자열로 표시하며 출력\n",
        "        print(evaluation_results_df[evaluated_metrics].round(4).to_string(na_rep='NaN'))\n",
        "\n",
        "        print(\"\\n=== 지표별 통계 (NaN 제외) ===\")\n",
        "        # describe()는 기본적으로 NaN 제외\n",
        "        stats = evaluation_results_df[evaluated_metrics].describe().round(4)\n",
        "        print(stats)\n",
        "\n",
        "        # NaN 발생 현황 집계\n",
        "        nan_counts = evaluation_results_df[evaluated_metrics].isna().sum()\n",
        "        if nan_counts.sum() > 0:\n",
        "             print(\"\\n[참고] NaN 발생 현황:\")\n",
        "             print(nan_counts[nan_counts > 0])\n",
        "             print(\"  (LLM 응답 오류, Timeout, 데이터 부족 등으로 점수 계산 불가 시 발생)\")\n",
        "        else:\n",
        "            print(\"\\n[정보] 모든 유효 항목에 대해 점수가 성공적으로 계산되었습니다.\")\n",
        "    else:\n",
        "        print(\"\\n!! 평가 결과 DataFrame에 요약할 유효한 메트릭 컬럼이 없습니다.\")\n",
        "\n",
        "    # 컬럼 매핑 정보 제공\n",
        "    print(f\"\\n**참고:**\")\n",
        "    if 'context_recall' in evaluated_metrics: print(f\"  - 'context_recall'은(는) Google Sheet '{GROUND_TRUTHS_COLUMN}' 컬럼을 참조했습니다.\")\n",
        "    if 'context_precision' in evaluated_metrics: print(f\"  - 'context_precision'은(는) Google Sheet '{ANSWER_COLUMN}' 컬럼 (-> 'reference')을 참조했습니다.\")\n",
        "\n",
        "else:\n",
        "    print(\"RAGAS 평가가 실행되지 않았거나 오류가 발생하여 요약할 결과가 없습니다.\")\n",
        "\n",
        "print(\"\\n--- 단계 13: Retriever 성능 평가 (RAGAS, Google Sheet) 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dvm1VAFQvMx"
      },
      "source": [
        "# 14: RAGAS 생성된 답변 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "cece34ddf24347fbb4dc37bcc778fe8c",
            "77aab44aceda4eaba82a67e1d64b2861",
            "520692abe1b64ffeb5bac3b2f029a89e",
            "74a2e8cdfae84488bda77d82e5824643",
            "b019aebe56ff4ec696e7c574380234f6",
            "da8f3754107846dab56fc92c54846a5e",
            "ac56272234454fe19b36c796935dcb30",
            "bdca233b16ee453eb7dae615f1f377d7",
            "729ed32c0f914cd98973add459272dd9",
            "d9bdcf4274e942d9b31599ad464b39ff",
            "185fea720646477c8e9f33e8e58a0865"
          ]
        },
        "id": "iUhFBfGMQskj",
        "outputId": "125475ec-7058-4946-938a-8b5ad0108f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 14: RAGAS 평가 시작 (Faithfulness, Answer Relevancy) ---\n",
            "[정보] RAGAS 및 관련 라이브러리 임포트 확인.\n",
            "\n",
            "--- 12.1: 평가 필요 객체 확인 ---\n",
            "\n",
            "--- 42.2: RAGAS 평가 데이터 준비 ---\n",
            "[성공] 평가용 데이터셋 생성 완료 (1개 항목).\n",
            "\n",
            "--- 12.3: RAGAS 평가 실행 ---\n",
            "평가 지표: ['faithfulness', 'answer_relevancy']\n",
            "RAGAS 평가 실행 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cece34ddf24347fbb4dc37bcc778fe8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[성공] RAGAS 평가 완료.\n",
            "\n",
            "--- 14.4: RAGAS 평가 결과 ---\n",
            "{'faithfulness': 1.0000, 'answer_relevancy': 0.7607}\n",
            "\n",
            "**지표 설명:**\n",
            "  - faithfulness: 답변이 제공된 컨텍스트 문서 내용에 얼마나 기반하는지 (높을수록 좋음,幻覺 적음)\n",
            "  - answer_relevancy: 생성된 답변이 원본 질문과 얼마나 관련성이 높은지 (높을수록 좋음)\n",
            "\n",
            "--- 단계 14: RAGAS 평가 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# === 단계 14: RAGAS 평가 (생성된 답변 대상) ===\n",
        "# 이 블록은 단계 11에서 RAG 시스템 실행(qa_chain.invoke) 후 실행해야 합니다.\n",
        "\n",
        "print(\"\\n--- 단계 14: RAGAS 평가 시작 (Faithfulness, Answer Relevancy) ---\")\n",
        "\n",
        "# 필요한 라이브러리 임포트 (이전 블록에서 임포트했더라도 명시적으로 다시 확인)\n",
        "import warnings\n",
        "from datasets import Dataset\n",
        "# RAGAS 관련 임포트 (오류 발생 시 메시지 출력하며 None으로 설정)\n",
        "try:\n",
        "    from ragas import evaluate\n",
        "    from ragas.metrics import faithfulness, answer_relevancy\n",
        "    from ragas.llms import LangchainLLMWrapper\n",
        "    from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "    print(\"[정보] RAGAS 및 관련 라이브러리 임포트 확인.\")\n",
        "except ImportError as e:\n",
        "    print(f\"!! [오류] RAGAS 관련 라이브러리 임포트 실패: {e}\")\n",
        "    print(\"   이전 단계의 라이브러리 설치가 성공했는지, 런타임 재시작이 필요한지 확인하세요.\")\n",
        "    evaluate = None; faithfulness = None; answer_relevancy = None;\n",
        "    LangchainLLMWrapper = None; LangchainEmbeddingsWrapper = None\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") # 경고 메시지 숨기기\n",
        "\n",
        "# --- 14.1: 평가에 필요한 객체 및 데이터 확인 ---\n",
        "print(\"\\n--- 12.1: 평가 필요 객체 확인 ---\")\n",
        "\n",
        "# 이전 단계(Step 11)에서 생성된 결과 확인\n",
        "rag_execution_successful = ('query' in locals() and query and\n",
        "                           'result' in locals() and isinstance(result, dict) and\n",
        "                           'result' in result and 'source_documents' in result)\n",
        "\n",
        "# 평가에 필요한 LLM 및 Embedding 모델 확인 (이전 단계에서 정의됨)\n",
        "llm_available = 'llm' in locals() and llm is not None\n",
        "embeddings_available = 'embeddings' in locals() and embeddings is not None\n",
        "\n",
        "if not rag_execution_successful:\n",
        "    print(\"!! [오류] 이전 단계(단계 11)의 RAG 실행 결과('query', 'result') 없음. 평가 불가.\")\n",
        "if not llm_available:\n",
        "    print(\"!! [오류] 평가용 LLM 객체('llm') 없음. 평가 불가.\")\n",
        "if not embeddings_available:\n",
        "    print(\"!! [경고] 평가용 Embedding 객체('embeddings') 없음. 'answer_relevancy' 계산 불가.\")\n",
        "\n",
        "# 모든 필수 요소가 준비되었는지 최종 확인\n",
        "ready_for_evaluation = (rag_execution_successful and llm_available and embeddings_available and\n",
        "                        evaluate and faithfulness and answer_relevancy and\n",
        "                        LangchainLLMWrapper and LangchainEmbeddingsWrapper) # RAGAS 함수/클래스 임포트 확인\n",
        "\n",
        "# --- 14.2: RAGAS 평가 데이터 준비 ---\n",
        "eval_dataset = None\n",
        "if ready_for_evaluation:\n",
        "    print(\"\\n--- 42.2: RAGAS 평가 데이터 준비 ---\")\n",
        "    try:\n",
        "        # Step 11의 결과를 RAGAS가 요구하는 형식으로 변환\n",
        "        eval_data = {\n",
        "            'question': [query],  # Step 11의 질문 (리스트 형태)\n",
        "            'answer': [result['result']], # Step 11의 생성된 답변 (리스트 형태)\n",
        "            'contexts': [[doc.page_content for doc in result['source_documents']]], # 검색된 문서 내용 리스트 (리스트의 리스트 형태)\n",
        "            # 'ground_truth': [\"여기에 이상적인 정답 문자열을 넣을 수 있습니다\"] # (선택 사항) 만약 이상적인 정답이 있다면 추가\n",
        "        }\n",
        "        eval_dataset = Dataset.from_dict(eval_data)\n",
        "        print(\"[성공] 평가용 데이터셋 생성 완료 (1개 항목).\")\n",
        "        # print(\"  샘플 데이터:\", eval_dataset[0]) # 디버깅용\n",
        "    except Exception as e:\n",
        "        print(f\"!! [오류] 평가 데이터셋 생성 중 오류: {e}\")\n",
        "        eval_dataset = None\n",
        "        ready_for_evaluation = False # 데이터 준비 실패 시 평가 불가\n",
        "\n",
        "# --- 14.3: RAGAS 평가 실행 ---\n",
        "evaluation_results = None\n",
        "if ready_for_evaluation:\n",
        "    print(\"\\n--- 12.3: RAGAS 평가 실행 ---\")\n",
        "    try:\n",
        "        # RAGAS Metric 정의 (이 평가에서는 답변 품질 지표만 사용)\n",
        "        metrics_to_evaluate = [\n",
        "            faithfulness,     # 답변이 컨텍스트에 얼마나 충실한가 (LLM 필요)\n",
        "            answer_relevancy  # 답변이 질문과 얼마나 관련 있는가 (LLM 및 Embeddings 필요)\n",
        "        ]\n",
        "        print(f\"평가 지표: {[m.name for m in metrics_to_evaluate]}\")\n",
        "\n",
        "        # RAGAS 래퍼 초기화 (이전 Ragas 평가 블록과 유사)\n",
        "        # LLM 래퍼\n",
        "        ragas_llm_eval = LangchainLLMWrapper(llm)\n",
        "        # Embedding 래퍼\n",
        "        ragas_embeddings_eval = LangchainEmbeddingsWrapper(embeddings)\n",
        "\n",
        "        # 평가 실행\n",
        "        print(\"RAGAS 평가 실행 중...\")\n",
        "        evaluation_results = evaluate(\n",
        "            dataset=eval_dataset,\n",
        "            metrics=metrics_to_evaluate,\n",
        "            llm=ragas_llm_eval,\n",
        "            embeddings=ragas_embeddings_eval # answer_relevancy에 필요\n",
        "            # is_async=False # Colab 등에서 동시성 문제 발생 시 False 시도\n",
        "        )\n",
        "        print(\"[성공] RAGAS 평가 완료.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!! [오류] RAGAS 평가 실행 중 오류 발생: {e}\")\n",
        "        print(\"   - API 키 유효성, 할당량(Rate Limit), 네트워크 연결 확인 필요.\")\n",
        "        print(\"   - LLM/Embedding 모델 호환성 또는 RAGAS 버전 문제일 수 있음.\")\n",
        "        traceback.print_exc() # 상세 오류 스택 출력\n",
        "        evaluation_results = None\n",
        "else:\n",
        "    print(\"\\n!! 필수 요소 부족으로 RAGAS 평가를 건너<0xEB><0x9B><0x81>니다.\")\n",
        "\n",
        "\n",
        "# --- 14.4: 평가 결과 출력 ---\n",
        "print(\"\\n--- 14.4: RAGAS 평가 결과 ---\")\n",
        "if evaluation_results:\n",
        "    # Ragas 결과는 딕셔너리 형태일 수 있음 (최신 버전 확인 필요)\n",
        "    if isinstance(evaluation_results, dict):\n",
        "        print(\"{\")\n",
        "        for metric_name, score in evaluation_results.items():\n",
        "             # NaN 값 처리 추가\n",
        "             score_str = f\"{score:.4f}\" if isinstance(score, (int, float)) and not np.isnan(score) else \"NaN\"\n",
        "             print(f\"  '{metric_name}': {score_str},\")\n",
        "        print(\"}\")\n",
        "    else:\n",
        "         # DataFrame 등으로 반환될 경우 처리\n",
        "         print(evaluation_results)\n",
        "\n",
        "    print(\"\\n**지표 설명:**\")\n",
        "    print(\"  - faithfulness: 답변이 제공된 컨텍스트 문서 내용에 얼마나 기반하는지 (높을수록 좋음,幻覺 적음)\")\n",
        "    print(\"  - answer_relevancy: 생성된 답변이 원본 질문과 얼마나 관련성이 높은지 (높을수록 좋음)\")\n",
        "else:\n",
        "    print(\"평가 결과가 없습니다.\")\n",
        "\n",
        "print(\"\\n--- 단계 14: RAGAS 평가 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-F0chBxRoP4"
      },
      "source": [
        "# 15: 정성적 평가 (LLM-as-Judge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tX1JDcHgl8w",
        "outputId": "98ffa5f3-d862-4380-937c-5c38a06cbf58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 단계 14: 정성적 평가 (LLM-as-Judge) 시작 ---\n",
            "\n",
            "--- 15.1: 필요한 라이브러리 및 객체 확인 ---\n",
            "\n",
            "--- 15.2: 평가 실행 ---\n",
            "[정보] 평가자 LLM: gpt-4.1\n",
            "\n",
            "LLM 기반 정성적 평가 진행 중...\n",
            "\n",
            "[LLM 평가 결과 (Raw)]:\n",
            " {\n",
            "    \"faithfulness\": {\n",
            "        \"score\": \"No\",\n",
            "        \"justification\": \"답변에서 '주 40시간(1일 8시간, 1주 5일 기준)' 등 구체적인 기준, '근로자의 날' 등 일부 내용, 그리고 '근로계약서 또는 회사 내규를 확인할 필요' 등은 컨텍스트 문서에 명시적으로 언급되어 있지 않습니다. 또한, 토요일/일요일의 구체적 적용 예시도 컨텍스트에 근거가 부족합니다.\"\n",
            "    },\n",
            "    \"relevance\": {\n",
            "        \"score\": \"Yes\",\n",
            "        \"justification\": \"질문이 주말 근로의 수당 종류와 계산 방법에 관한 것인데, 답변이 이에 대해 직접적으로 설명하고 있습니다.\"\n",
            "    },\n",
            "    \"clarity\": {\n",
            "        \"score\": \"Yes\",\n",
            "        \"justification\": \"답변이 단계별로 설명되어 있고, 예시를 들어 이해하기 쉽게 작성되었습니다.\"\n",
            "    },\n",
            "    \"completeness\": {\n",
            "        \"score\": \"No\",\n",
            "        \"justification\": \"컨텍스트 문서에 있는 '적법한 휴일대체 시 휴일근로수당 지급 의무 없음', '대법원 판례', '사후 대체휴일 부여 시에도 가산수당 발생' 등 중요한 예외 및 판례 정보가 답변에 충분히 반영되지 않았습니다.\"\n",
            "    }\n",
            "}\n",
            "\n",
            "[파싱된 평가 결과]:\n",
            "- Faithfulness:\n",
            "  - 점수: No\n",
            "  - 근거: 답변에서 '주 40시간(1일 8시간, 1주 5일 기준)' 등 구체적인 기준, '근로자의 날' 등 일부 내용, 그리고 '근로계약서 또는 회사 내규를 확인할 필요' 등은 컨텍스트 문서에 명시적으로 언급되어 있지 않습니다. 또한, 토요일/일요일의 구체적 적용 예시도 컨텍스트에 근거가 부족합니다.\n",
            "- Relevance:\n",
            "  - 점수: Yes\n",
            "  - 근거: 질문이 주말 근로의 수당 종류와 계산 방법에 관한 것인데, 답변이 이에 대해 직접적으로 설명하고 있습니다.\n",
            "- Clarity:\n",
            "  - 점수: Yes\n",
            "  - 근거: 답변이 단계별로 설명되어 있고, 예시를 들어 이해하기 쉽게 작성되었습니다.\n",
            "- Completeness:\n",
            "  - 점수: No\n",
            "  - 근거: 컨텍스트 문서에 있는 '적법한 휴일대체 시 휴일근로수당 지급 의무 없음', '대법원 판례', '사후 대체휴일 부여 시에도 가산수당 발생' 등 중요한 예외 및 판례 정보가 답변에 충분히 반영되지 않았습니다.\n",
            "\n",
            "--- 단계 15: 정성적 평가 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# === 단계 15: 정성적 평가 (LLM-as-Judge) ===\n",
        "# (ChatOpenAI 사용에 맞게 수정됨)\n",
        "\n",
        "# 이 블록은 단계 11에서 RAG 시스템 실행(qa_chain.invoke 또는 __call__) 후 실행해야 합니다.\n",
        "\n",
        "print(\"\\n--- 단계 14: 정성적 평가 (LLM-as-Judge) 시작 ---\") # <<< 단계 번호 수정\n",
        "\n",
        "# --- 15.1: 필요한 라이브러리 및 객체 확인 ---\n",
        "print(\"\\n--- 15.1: 필요한 라이브러리 및 객체 확인 ---\") # <<< 단계 번호 수정\n",
        "import json\n",
        "import traceback\n",
        "import re # JSON 추출 위해 임포트 추가\n",
        "# LangChain 관련 (이미 임포트 되었을 가능성 높음, 확인 차원)\n",
        "try: from langchain.prompts import PromptTemplate\n",
        "except ImportError: print(\"!! [오류] langchain.prompts 임포트 실패\")\n",
        "# LLM 클래스 확인 (ChatOpenAI)\n",
        "try: from langchain_openai import ChatOpenAI\n",
        "except ImportError: print(\"!! [오류] langchain_openai.ChatOpenAI 임포트 실패\")\n",
        "\n",
        "# 이전 단계 결과 확인\n",
        "rag_execution_successful = ('query' in locals() and query and\n",
        "                           'result' in locals() and isinstance(result, dict) and\n",
        "                           'result' in result and 'source_documents' in result)\n",
        "# 평가자 LLM 확인 (단계 9에서 정의된 llm 사용)\n",
        "llm_available = 'llm' in locals() and llm is not None and isinstance(llm, ChatOpenAI) # 타입 확인 추가\n",
        "\n",
        "if not rag_execution_successful:\n",
        "    print(\"!! [오류] 이전 단계(단계 11)의 RAG 실행 결과('query', 'result') 없음. 평가 불가.\")\n",
        "if not llm_available:\n",
        "    print(\"!! [오류] 평가용 LLM 객체('llm')가 없거나 ChatOpenAI 타입이 아님. 평가 불가.\")\n",
        "\n",
        "# --- 15.2: 평가 실행 ---\n",
        "print(\"\\n--- 15.2: 평가 실행 ---\") # <<< 단계 번호 수정\n",
        "if rag_execution_successful and llm_available:\n",
        "    # 평가에 사용할 LLM (기존 llm 사용)\n",
        "    evaluator_llm = llm\n",
        "    # 만약 다른 강력한 모델을 쓰고 싶다면 여기서 재정의\n",
        "    # evaluator_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "    # ====> 수정된 부분: .model 대신 .model_name 사용 <====\n",
        "    print(f\"[정보] 평가자 LLM: {evaluator_llm.model_name}\")\n",
        "    # ===============================================\n",
        "\n",
        "    # 평가 데이터 추출\n",
        "    rag_answer = result.get(\"result\", \"\")\n",
        "    source_docs = result.get(\"source_documents\", []) # source_documents가 없다면 이전 단계 문제\n",
        "    if not source_docs:\n",
        "         print(\"!! [경고] result 객체에 'source_documents'가 비어있거나 없습니다. 컨텍스트 없는 평가 진행.\")\n",
        "         context_str = \"\" # 컨텍스트 없이 진행\n",
        "    else:\n",
        "         context_str = \"\\n\\n\".join([doc.page_content for doc in source_docs])\n",
        "\n",
        "    # 평가 프롬프트 템플릿 (기존 유지)\n",
        "    evaluation_template = \"\"\"당신은 AI 응답 품질 평가 전문가입니다. 주어진 '질문', '컨텍스트 문서', 그리고 AI가 생성한 '답변'을 바탕으로 다음 기준에 따라 답변의 품질을 평가해주세요. 평가는 '컨텍스트 문서'에 있는 내용만을 근거로 해야 합니다.\n",
        "\n",
        "    [평가 기준]\n",
        "    1.  **Faithfulness (충실성):** 답변이 '컨텍스트 문서' 내용에만 기반하고 있습니까? 외부 정보를 추가하거나 컨텍스트와 모순되는 내용은 없습니까? (Yes/No)\n",
        "    2.  **Relevance (관련성):** 답변이 사용자의 '질문'과 직접적으로 관련이 있습니까? (Yes/No)\n",
        "    3.  **Clarity (명확성):** 답변이 명확하고 간결하며 이해하기 쉽습니까? (Yes/No)\n",
        "    4.  **Completeness (완전성 - 컨텍스트 기준):** 답변이 '컨텍스트 문서' 내에서 찾을 수 있는 정보 범위 내에서 '질문'에 대해 충분히 완전하게 답변하고 있습니까? (Yes/No)\n",
        "\n",
        "    [입력 정보]\n",
        "    질문: {question}\n",
        "\n",
        "    컨텍스트 문서:\n",
        "    {context}\n",
        "\n",
        "    AI 생성 답변: {answer}\n",
        "\n",
        "    [평가 결과 출력]\n",
        "    각 평가 기준에 대해 \"Yes\" 또는 \"No\"로 평가하고, 각 평가에 대한 간략한 근거를 포함하여 JSON 형식으로 결과를 반환해주세요.\n",
        "    예시: {{\n",
        "        \"faithfulness\": {{\\\"score\\\": \\\"Yes\\\", \\\"justification\\\": \\\"답변 내용이 모두 컨텍스트 문서에서 확인되었습니다.\\\"}},\n",
        "        \"relevance\": {{\\\"score\\\": \\\"Yes\\\", \\\"justification\\\": \\\"질문의 핵심 내용을 정확히 파악하고 답변했습니다.\\\"}},\n",
        "        \"clarity\": {{\\\"score\\\": \\\"Yes\\\", \\\"justification\\\": \\\"간결하고 명확한 문장으로 작성되었습니다.\\\"}},\n",
        "        \"completeness\": {{\\\"score\\\": \\\"No\\\", \\\"justification\\\": \\\"질문의 일부 측면(예: 예외 사항)에 대한 정보가 컨텍스트에 있었으나 답변에 포함되지 않았습니다.\\\"}}\n",
        "    }}\n",
        "\n",
        "    JSON 출력:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        EVALUATION_PROMPT = PromptTemplate.from_template(evaluation_template)\n",
        "    except NameError:\n",
        "         print(\"!! [오류] PromptTemplate 클래스를 찾을 수 없습니다. 단계 1 임포트를 확인하세요.\")\n",
        "         EVALUATION_PROMPT = None\n",
        "\n",
        "    # 평가 체인 구성 및 실행\n",
        "    if EVALUATION_PROMPT:\n",
        "        try:\n",
        "            print(\"\\nLLM 기반 정성적 평가 진행 중...\")\n",
        "            eval_chain = EVALUATION_PROMPT | evaluator_llm # LangChain Expression Language 사용\n",
        "\n",
        "            # 컨텍스트 길이 제한 (평가자 LLM의 토큰 제한 고려)\n",
        "            # GPT-4o는 긴 컨텍스트 처리 가능 (예: 128k), 비용 및 효율성 위해 제한 가능\n",
        "            max_context_length = 100000 # 예시: 필요시 조정 (GPT-4o에 맞춰 늘림)\n",
        "            if len(context_str) > max_context_length:\n",
        "                print(f\"  [경고] 컨텍스트 길이가 길어 {max_context_length}자로 잘라냅니다.\")\n",
        "                context_for_eval = context_str[:max_context_length]\n",
        "            else:\n",
        "                context_for_eval = context_str\n",
        "                if not context_for_eval: # source_documents 없을 경우\n",
        "                    print(\"  [정보] 컨텍스트 문서 없이 평가 진행.\")\n",
        "\n",
        "            # 입력값 준비\n",
        "            chain_input = {\n",
        "                \"question\": query if query else \"질문 정보 없음\", # query 변수 확인\n",
        "                \"context\": context_for_eval,\n",
        "                \"answer\": rag_answer if rag_answer else \"답변 정보 없음\" # rag_answer 변수 확인\n",
        "            }\n",
        "\n",
        "            eval_result_str = eval_chain.invoke(chain_input).content\n",
        "\n",
        "            print(\"\\n[LLM 평가 결과 (Raw)]:\\n\", eval_result_str)\n",
        "\n",
        "            # JSON 파싱 시도 및 결과 출력\n",
        "            print(\"\\n[파싱된 평가 결과]:\")\n",
        "            try:\n",
        "                # LLM 응답에서 JSON 부분만 추출 (마크다운 ```json ... ``` 고려)\n",
        "                match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', eval_result_str, re.DOTALL | re.IGNORECASE)\n",
        "                if match:\n",
        "                    json_str = match.group(1)\n",
        "                else:\n",
        "                    # 코드 블록 없으면, 응답 시작이 '{' 인지 확인\n",
        "                    json_str = eval_result_str.strip()\n",
        "                    # 가끔 LLM이 JSON 앞에 불필요한 텍스트를 붙일 수 있으므로, '{' 를 찾아 시작점 조정 시도\n",
        "                    start_brace = json_str.find('{')\n",
        "                    if start_brace != -1:\n",
        "                        json_str = json_str[start_brace:]\n",
        "                        # 마지막 '}' 이후 내용 제거 시도 (단순 구현)\n",
        "                        end_brace = json_str.rfind('}')\n",
        "                        if end_brace != -1:\n",
        "                             json_str = json_str[:end_brace+1]\n",
        "                        else:\n",
        "                             raise json.JSONDecodeError(\"닫는 중괄호 '}' 없음\", json_str, 0)\n",
        "                    else:\n",
        "                         raise json.JSONDecodeError(\"응답이 JSON 형식으로 시작하지 않음\", json_str, 0)\n",
        "\n",
        "                eval_data = json.loads(json_str)\n",
        "                for criterion, details in eval_data.items():\n",
        "                    # details가 딕셔너리 형태인지 확인\n",
        "                    if isinstance(details, dict):\n",
        "                         print(f\"- {str(criterion).capitalize()}:\") # 키가 문자열 아닐 수도 있으니 str() 추가\n",
        "                         print(f\"  - 점수: {details.get('score', 'N/A')}\")\n",
        "                         print(f\"  - 근거: {details.get('justification', 'N/A')}\")\n",
        "                    else:\n",
        "                         # 예상치 못한 형식일 경우 그대로 출력\n",
        "                         print(f\"- {str(criterion).capitalize()}: {details}\")\n",
        "\n",
        "            except json.JSONDecodeError as json_e:\n",
        "                print(f\"  !! 평가 결과가 유효한 JSON 형식이 아니거나 파싱 오류 발생: {json_e}\")\n",
        "                print(\"     Raw 결과를 직접 확인하세요.\")\n",
        "            except Exception as parse_e:\n",
        "                print(f\"  !! 평가 결과 처리 중 오류: {parse_e}\")\n",
        "                traceback.print_exc()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!! LLM 평가 실행 중 오류 발생: {e}\")\n",
        "            print(\"   - API 키, 할당량, 네트워크 연결 등을 확인하세요.\")\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"!! [오류] 평가 프롬프트 템플릿(EVALUATION_PROMPT) 생성 실패.\")\n",
        "\n",
        "else:\n",
        "    # 평가 실행 불가 사유 출력\n",
        "    print(\"\\n!! 이전 단계 결과 또는 LLM 객체가 준비되지 않아 정성적 평가를 진행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- 단계 15: 정성적 평가 완료 ---\") # <<< 단계 번호 수정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTXXRvZguv2H"
      },
      "source": [
        "# ✅회고\n",
        "\n",
        "챗봇의 성능을 평가하기 위해 총 12개의 질문을 엄선하여 Rewriter를 평가하였습니다.\n",
        "\n",
        "(근로자)\n",
        "\n",
        "1. 육아휴직은 꼭 1년 다 써야 하나요? 중간에 복귀할 수 있나요?\n",
        "\n",
        "2. 산업재해가 발생했을 때 근로자가 해야 할 일은 무엇인가요?\n",
        "\n",
        "3. 무료로 상담 가능한 노무사가 있나요? 어떻게 찾나요?\n",
        "\n",
        "4. 4인 이하 사업장인데 주휴수당 받을 수 있나요?\n",
        "\n",
        "5. 노무사가 대신 퇴직금 청구해줄 수 있나요, 아니면 변호사를 찾아야 하나요?\n",
        "\n",
        "6. 시급제로 일하는데, 주말에도 자주 일합니다. 주말 근로는 연장수당으로 쳐야 하나요, 휴일수당으로 쳐야 하나요? 계산 방법이 궁금합니다.\n",
        "\n",
        "\n",
        "(사업주)\n",
        "\n",
        "7. 퇴직금 지급 기한을 넘기면 어떤 불이익이 있나요?\n",
        "\n",
        "8. 산재 사고가 발생했을 때 바로 어떤 조치를 해야 하나요?\n",
        "\n",
        "9. 정규직 전환 의무가 발생하는 기간은 얼마인가요?\n",
        "\n",
        "10. 임산부 직원의 야간근로를 시키면 불법인가요?\n",
        "\n",
        "11. 육아휴직 중인 직원 대신 대체 인력을 뽑았을 때 주의할 점은 무엇인가요?\n",
        "\n",
        "12. 5인 미만 사업장인데, 근로자가 육아휴직을 신청했습니다. 의무적으로 승인해야 하나요? 불승인할 경우 법적 문제가 있나요?\n",
        "\n",
        "\n",
        "이 중 1번, 4번, 7번 문제에서 문서에 기반하지 않은 답변을 생성하였습니다.\n",
        "유저의 질문을 구체적인 장문의 법률 용어를 사용하여 재생성하게 되는데,\n",
        "이렇게 재생성된 질문이 너무 구체적이고 복잡해져서인지 문서를 잘못 기록하는 확률이 상승하였습니다.\n",
        "\n",
        "\n",
        "질문을 재생성하는 LLM의 프롬프트를 개선하면 성능이 향상될 수 있을 것으로 보입니다.\n",
        "다만, 보통 rag의 응답 생성 시간이 4~5초 이내인데 rewriter를 적용하면 7~8초 소요되어 챗봇으로 사용하기에는 한계가 있었습니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}